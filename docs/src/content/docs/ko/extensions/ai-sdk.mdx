---
title: AI SDK로 어떤 모델이든 사용
description: Connect your Agents SDK agents to any model through the Vercel's AI SDK
---

import { Aside, Steps, Code } from '@astrojs/starlight/components';
import aiSdkImportsExample from '../../../../../../examples/docs/extensions/ai-sdk-imports.ts?raw';
import aiSdkModelExample from '../../../../../../examples/docs/extensions/ai-sdk-model.ts?raw';
import aiSdkProviderDataExample from '../../../../../../examples/docs/extensions/ai-sdk-providerData.ts?raw';
import aiSdkProviderMetadataExample from '../../../../../../examples/docs/extensions/ai-sdk-providerMetadata.ts?raw';
import aiSdkSetupExample from '../../../../../../examples/docs/extensions/ai-sdk-setup.ts?raw';
import aiSdkUiMessageStreamResponseExample from '../../../../../../examples/docs/extensions/ai-sdk-ui-message-stream-response.ts?raw';
import aiSdkTextStreamResponseExample from '../../../../../../examples/docs/extensions/ai-sdk-text-stream-response.ts?raw';

<Aside type="caution">
  이 어댑터는 아직 베타입니다. 일부 모델 제공자, 특히 규모가 작은 제공자에서
  문제가 발생할 수 있습니다. 문제를 발견하면 [GitHub
  이슈](https://github.com/openai/openai-agents-js/issues)로 제보해 주세요.
  빠르게 수정하겠습니다.
</Aside>

Agents SDK는 기본적으로 Responses API 또는 Chat Completions API를 통해 OpenAI 모델과 함께 동작합니다. 하지만 다른 모델을 사용하고 싶다면, [Vercel AI SDK](https://sdk.vercel.ai/)가 지원하는 다양한 모델을 이 어댑터를 통해 Agents SDK에 연결할 수 있습니다.

## 설정

<Steps>

1. extensions 패키지를 설치해 AI SDK 어댑터를 설치합니다:

   ```bash
   npm install @openai/agents-extensions
   ```

2. [Vercel의 AI SDK](https://ai-sdk.dev/docs/foundations/providers-and-models)에서 원하는 모델 패키지를 선택해 설치합니다:

   ```bash
   npm install @ai-sdk/openai
   ```

3. 어댑터와 모델을 가져와 에이전트에 연결합니다:

   <Code lang="typescript" code={aiSdkImportsExample} title="어댑터 가져오기" />

4. 에이전트가 사용할 모델 인스턴스를 초기화합니다:

   <Code lang="typescript" code={aiSdkModelExample} title="모델 생성" />

</Steps>

<Aside type="caution">
  `specificationVersion` `v2` 또는 `v3`를 노출하는 AI SDK 제공자를 지원합니다.
  특별한 이유로 이전 v1 제공자 스타일을 계속 사용해야 한다면,
  [examples/ai-sdk-v1](https://github.com/openai/openai-agents-js/tree/main/examples/ai-sdk-v1)에서
  모듈을 복사해 프로젝트에 포함할 수 있습니다.
</Aside>

## 예제

<Code lang="typescript" code={aiSdkSetupExample} title="AI SDK 설정" />

## 제공자 메타데이터 전달

메시지와 함께 제공자별 옵션을 보내야 한다면 `providerMetadata`를 통해 전달하세요. 값은 하위 AI SDK 모델로 직접 전달됩니다. 예를 들어, Agents SDK의 다음 `providerData`는

<Code
  lang="typescript"
  code={aiSdkProviderDataExample}
  title="Agents SDK providerData"
/>

다음처럼 변환됩니다

<Code
  lang="typescript"
  code={aiSdkProviderMetadataExample}
  title="AI SDK providerMetadata"
/>

AI SDK 통합을 사용할 때 위와 같이 동작합니다.

## 적절한 통합 선택

`@openai/agents-extensions`에는 서로 관련된 두 가지 통합이 있습니다:

- `@openai/agents-extensions/ai-sdk`는 AI SDK 모델을 어댑트하여 `Agent`가 해당 모델에서 실행되도록 합니다.
- `@openai/agents-extensions/ai-sdk-ui`는 스트리밍된 Agents SDK 실행을 어댑트하여 AI SDK UI 라우트가 표준 스트리밍 `Response`를 반환하도록 합니다.

## AI SDK UI 스트림 헬퍼

`@openai/agents-extensions/ai-sdk-ui`는 Agents SDK 스트림을 AI SDK UI 라우트에 연결하기 위한 응답 헬퍼를 제공합니다:

- 일반 텍스트 스트리밍 응답용 `createAiSdkTextStreamResponse(source, options?)`
- `UIMessageChunk` 스트리밍 응답용 `createAiSdkUiMessageStreamResponse(source, options?)`

두 헬퍼 모두 `StreamedRunResult`, 스트림 유사 소스 또는 호환 래퍼 객체를 받아 스트리밍 친화적인 헤더가 포함된 `Response`를 반환합니다.

UI에서 도구 호출이나 추론 파트 같은 구조화된 청크가 필요하면 `createAiSdkUiMessageStreamResponse(...)`를 사용하세요. 일반 텍스트만 원하면 `createAiSdkTextStreamResponse(...)`를 사용하세요.

UI 메시지 스트리밍을 위한 Next.js 라우트 예제:

<Code
  lang="typescript"
  code={aiSdkUiMessageStreamResponseExample}
  title="UI 메시지 스트림 응답"
/>

텍스트 전용 스트리밍을 위한 Next.js 라우트 예제:

<Code
  lang="typescript"
  code={aiSdkTextStreamResponseExample}
  title="텍스트 스트림 응답"
/>

엔드 투 엔드 사용법은 이 저장소의 `examples/ai-sdk-ui` 앱을 참고하세요.
