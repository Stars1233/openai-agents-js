---
title: 세션
description: Persist multi-turn conversation history so agents can resume context across runs.
---

import { Code } from '@astrojs/starlight/components';
import sessionsQuickstart from '../../../../../../examples/docs/sessions/basicSession.ts?raw';
import manageHistory from '../../../../../../examples/docs/sessions/manageHistory.ts?raw';
import customSession from '../../../../../../examples/docs/sessions/customSession.ts?raw';
import sessionInputCallback from '../../../../../../examples/docs/sessions/sessionInputCallback.ts?raw';
import responsesCompactionSession from '../../../../../../examples/docs/sessions/responsesCompactionSession.ts?raw';
import manualCompactionSession from '../../../../../../examples/docs/sessions/responsesCompactionManualSession.ts?raw';

세션은 Agents SDK에 **지속 메모리 계층**을 제공합니다. `Runner.run`에 `Session` 인터페이스를 구현한 객체를 전달하면, 나머지는 SDK가 처리합니다. 세션이 있으면 러너는 자동으로 다음을 수행합니다:

1. 이전에 저장된 대화 항목을 가져와 다음 턴 앞에 추가
2. 각 실행이 완료된 후 새로운 사용자 입력과 어시스턴트 출력을 영속화
3. 새로운 사용자 텍스트로 러너를 호출하든, `RunState`의 인터럽션(중단 처리)에서 재개하든, 이후 턴을 위해 세션을 유지

이로써 `toInputList()`를 수동으로 호출하거나 턴 사이의 기록을 직접 이어 붙일 필요가 없습니다. TypeScript SDK에는 두 가지 구현이 포함되어 있습니다: Conversations API용 `OpenAIConversationsSession`과 로컬 개발용 `MemorySession`. 두 구현은 `Session` 인터페이스를 공유하므로, 자체 스토리지 백엔드를 연결할 수 있습니다. Conversations API 외의 영감이 필요하다면 `examples/memory/` 아래의 샘플 세션 백엔드(Prisma, 파일 백업 등)를 살펴보세요. OpenAI Responses 모델을 사용할 때는, `OpenAIResponsesCompactionSession`으로 어떤 세션이든 래핑하여 [`responses.compact`](https://platform.openai.com/docs/api-reference/responses/compact)를 통해 저장된 대화록을 자동으로 축소하세요.

> 팁: 이 페이지의 `OpenAIConversationsSession` 예제를 실행하려면 `OPENAI_API_KEY` 환경 변수를 설정하세요(또는 세션을 생성할 때 `apiKey`를 제공). 그러면 SDK가 Conversations API를 호출할 수 있습니다.

---

## 시작하기

### 빠른 시작

`OpenAIConversationsSession`을 사용하여 [Conversations API](https://platform.openai.com/docs/api-reference/conversations)와 메모리를 동기화하거나, 다른 어떤 `Session` 구현으로 교체하세요.

<Code
  lang="typescript"
  code={sessionsQuickstart}
  title="Conversations API를 세션 메모리로 사용하기"
/>

같은 세션 인스턴스를 재사용하면, 매 턴마다 에이전트가 전체 대화 기록을 받고 새로운 항목이 자동으로 영속화됩니다. 다른 `Session` 구현으로 전환해도 코드 변경은 필요하지 않습니다.

`OpenAIConversationsSession` 생성자 옵션:

| Option           | Type     | Notes                                                      |
| ---------------- | -------- | ---------------------------------------------------------- |
| `conversationId` | `string` | 새로운 대화를 지연 생성하는 대신 기존 대화를 재사용합니다. |
| `client`         | `OpenAI` | 사전 구성된 OpenAI 클라이언트를 전달합니다.                |
| `apiKey`         | `string` | 내부 OpenAI 클라이언트를 생성할 때 사용할 API 키입니다.    |
| `baseURL`        | `string` | OpenAI 호환 엔드포인트의 기본 URL입니다.                   |
| `organization`   | `string` | 요청에 사용할 OpenAI 조직 ID입니다.                        |
| `project`        | `string` | 요청에 사용할 OpenAI 프로젝트 ID입니다.                    |

세션을 생성하기 전에 대화 ID를 미리 만들어야 한다면
`startOpenAIConversationsSession(client?)`을 사용하고 반환된 ID를 `conversationId`로 전달하세요.

---

## 코어 세션 동작

### 러너의 세션 사용 방식

- **각 실행 전** 세션 기록을 가져와 새 턴의 입력과 병합하고, 결합된 목록을 에이전트에 전달
- **비 스트리밍 실행 후** 한 번의 `session.addItems()` 호출로 최신 턴의 원본 사용자 입력과 모델 출력을 모두 영속화
- **스트리밍 실행의 경우** 먼저 사용자 입력을 기록하고, 턴이 완료되면 스트리밍된 출력을 추가
- **`RunResult.state`에서 재개할 때**(승인 또는 기타 인터럽션) 동일한 `session`을 계속 전달. 재개된 턴은 입력을 다시 준비하지 않고 메모리에 추가됨

---

### 기록 검사 및 편집

세션은 간단한 CRUD 도우미를 제공하므로 "실행 취소", "채팅 지우기", 감사 기능을 구축할 수 있습니다.

<Code lang="typescript" code={manageHistory} title="저장된 항목 읽기 및 편집" />

`session.getItems()`는 저장된 `AgentInputItem[]`을 반환합니다. `popItem()`을 호출하면 마지막 항목을 제거합니다. 에이전트를 다시 실행하기 전에 사용자 정정에 유용합니다.

---

## 사용자 정의 스토리지 및 병합 동작

### 스토리지 직접 제공

`Session` 인터페이스를 구현하여 Redis, DynamoDB, SQLite 또는 기타 데이터스토어로 메모리를 지원하세요. 필요한 것은 다섯 가지 비동기 메서드뿐입니다.

<Code
  lang="typescript"
  code={customSession}
  title="사용자 정의 인메모리 세션 구현"
/>

커스텀 세션을 사용하면 보존 정책을 강제하고, 암호화를 추가하고, 영속화 전에 각 대화 턴에 메타데이터를 첨부할 수 있습니다.

---

### 기록과 새 항목의 병합 제어

실행 입력으로 `AgentInputItem` 배열을 전달할 때, `sessionInputCallback`을 제공하여 저장된 기록과 결정적으로 병합하세요. 러너는 기존 기록을 로드하고, **모델 호출 이전에** 콜백을 호출하며, 반환된 배열을 해당 턴의 전체 입력으로 모델에 전달합니다. 이 훅은 오래된 항목을 잘라내거나, 도구 결과를 중복 제거하거나, 모델이 보길 원하는 컨텍스트만 강조하는 데 적합합니다.

<Code
  lang="typescript"
  code={sessionInputCallback}
  title="sessionInputCallback으로 기록 자르기"
/>

문자열 입력의 경우 러너가 기록을 자동으로 병합하므로 콜백은 선택 사항입니다.

---

## 재개 가능한 실행

### 승인 및 재개 가능한 실행 처리

휴먼인더루프(HITL) 플로우는 종종 승인을 기다리기 위해 실행을 일시 중지합니다:

```typescript
const result = await runner.run(agent, 'Search the itinerary', {
  session,
  stream: true,
});

if (result.requiresApproval) {
  // ... collect user feedback, then resume the agent in a later turn
  const continuation = await runner.run(agent, result.state, { session });
  console.log(continuation.finalOutput);
}
```

이전 `RunState`에서 재개하면, 단일 대화 기록을 유지하기 위해 새 턴이 동일한 메모리 레코드에 추가됩니다. 휴먼인더루프(HITL) 플로우와의 호환성은 완전하게 유지됩니다. 승인 체크포인트는 여전히 `RunState`를 통해 라운드트립하고, 세션은 대화록을 완전하게 유지합니다.

---

## 고급: 대화록 압축

### OpenAI Responses 기록 자동 압축

`OpenAIResponsesCompactionSession`은 어떤 `Session`에도 데코레이트되어 대화록을 짧게 유지하기 위해 OpenAI Responses API에 의존합니다. 각 턴이 영속화된 후 러너는 최신 `responseId`를 `runCompaction`에 전달하며, 결정 훅이 true를 반환하면 `responses.compact`를 호출합니다. 기본 트리거는 사용자 이외 항목이 최소 10개 누적되면 압축을 수행합니다. 토큰 수나 사용자 정의 휴리스틱에 기반하도록 `shouldTriggerCompaction`을 오버라이드하세요. 이 데코레이터는 압축된 출력으로 기본 세션을 지우고 다시 쓰므로, 서버 관리형 기록 흐름을 사용하는 `OpenAIConversationsSession`과 함께 사용하는 것은 피하세요.

<Code
  lang="typescript"
  code={responsesCompactionSession}
  title="OpenAIResponsesCompactionSession으로 세션 데코레이트"
/>

`OpenAIResponsesCompactionSession` 생성자 옵션:

| Option                    | Type                                          | Notes                                                                                              |
| ------------------------- | --------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| `client`                  | `OpenAI`                                      | `responses.compact`에 사용할 OpenAI 클라이언트입니다.                                              |
| `underlyingSession`       | `Session`                                     | 압축된 항목으로 지우고/다시 쓸 백업 세션 스토어입니다(`OpenAIConversationsSession`이면 안 됩니다). |
| `model`                   | `OpenAI.ResponsesModel`                       | 압축 요청에 사용할 모델입니다.                                                                     |
| `compactionMode`          | `'auto' \| 'previous_response_id' \| 'input'` | 서버 응답 체이닝을 사용할지 로컬 입력 항목을 사용할지 등 압축 방식을 제어합니다.                   |
| `shouldTriggerCompaction` | `(context) => boolean \| Promise<boolean>`    | `responseId`, `compactionMode`, 후보 항목, 현재 세션 항목에 기반한 사용자 정의 트리거 훅입니다.    |

`runCompaction(args)` 옵션:

| Option           | Type                                          | Notes                                                                    |
| ---------------- | --------------------------------------------- | ------------------------------------------------------------------------ |
| `responseId`     | `string`                                      | `previous_response_id` 모드에서 사용할 최신 Responses API 응답 ID입니다. |
| `compactionMode` | `'auto' \| 'previous_response_id' \| 'input'` | 구성된 모드를 호출 단위로 오버라이드하는 선택적 옵션입니다.              |
| `store`          | `boolean`                                     | 마지막 실행이 서버 상태를 저장했는지 나타냅니다.                         |
| `force`          | `boolean`                                     | `shouldTriggerCompaction`을 우회하고 즉시 압축합니다.                    |

#### 저지연 스트리밍을 위한 수동 압축

압축은 기본 세션을 지우고 다시 쓰므로, SDK는 스트리밍 실행을 resolve하기 전에 이를 기다립니다. 압축 부담이 크면 마지막 출력 토큰 이후에도 `result.completed`가 몇 초간 보류될 수 있습니다. 저지연 스트리밍이나 더 빠른 턴 전환이 필요하다면 자동 압축을 비활성화하고 턴 사이(또는 유휴 시간)에 직접 `runCompaction`을 호출하세요.

<Code
  lang="typescript"
  code={manualCompactionSession}
  title="자동 압축 비활성화 후 턴 사이에 압축 수행"
/>

보관 또는 핸드오프 전에 기록을 축소하려면 언제든 `runCompaction({ force: true })`를 호출할 수 있습니다. `DEBUG=openai-agents:openai:compaction`으로 디버그 로그를 활성화하여 압축 결정을 추적하세요.
