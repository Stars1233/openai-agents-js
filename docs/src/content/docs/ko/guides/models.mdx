---
title: 모델
description: Choose and configure language models for your agents
---

import { Code } from '@astrojs/starlight/components';
import modelCustomProviderExample from '../../../../../../examples/docs/models/customProviders.ts?raw';
import setDefaultOpenAIKeyExample from '../../../../../../examples/docs/config/setDefaultOpenAIKey.ts?raw';
import modelSettingsExample from '../../../../../../examples/docs/models/modelSettings.ts?raw';
import promptIdExample from '../../../../../../examples/basic/prompt-id.ts?raw';
import agentWithModelExample from '../../../../../../examples/docs/models/agentWithModel.ts?raw';
import runnerWithModelExample from '../../../../../../examples/docs/models/runnerWithModel.ts?raw';
import gpt5DefaultModelSettingsExample from '../../../../../../examples/docs/models/gpt5DefaultModelSettings.ts?raw';
import setTracingExportApiKeyExample from '../../../../../../examples/docs/config/setTracingExportApiKey.ts?raw';

모든 에이전트는 궁극적으로 LLM을 호출합니다. SDK는 두 가지 경량 인터페이스 뒤에 모델을 추상화합니다:

- [`Model`](/openai-agents-js/openai/agents/interfaces/model) – 특정 API에 대해 _하나의_ 요청을 수행하는 방법을 알고 있음
- [`ModelProvider`](/openai-agents-js/openai/agents/interfaces/modelprovider) – 사람이 읽을 수 있는 모델 **이름**(예: `'gpt‑5.2'`)을 `Model` 인스턴스로 해석

일상적인 작업에서는 보통 모델 **이름**만 사용하며, 가끔 `ModelSettings`를 다룹니다.

<Code
  lang="typescript"
  code={agentWithModelExample}
  title="에이전트별 모델 지정"
/>

## 기본 모델

`Agent`를 초기화할 때 모델을 지정하지 않으면 기본 모델이 사용됩니다. 현재 기본값은 호환성과 낮은 지연 시간을 위해 [`gpt-4.1`](https://platform.openai.com/docs/models/gpt-4.1)입니다. 액세스 권한이 있다면, 더 높은 품질을 위해 에이전트를 [`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2)로 설정하고 명시적으로 `modelSettings`를 유지하는 것을 권장합니다.

[`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2) 같은 다른 모델로 전환하려면, 에이전트를 구성하는 방법은 두 가지가 있습니다.

먼저, 커스텀 모델을 설정하지 않은 모든 에이전트에 대해 일관되게 특정 모델을 사용하려면, 에이전트를 실행하기 전에 `OPENAI_DEFAULT_MODEL` 환경 변수를 설정하세요.

```bash
export OPENAI_DEFAULT_MODEL=gpt-5.2
node my-awesome-agent.js
```

둘째, `Runner` 인스턴스에 기본 모델을 설정할 수 있습니다. 에이전트에 모델을 설정하지 않으면 이 `Runner`의 기본 모델이 사용됩니다.

<Code
  lang="typescript"
  code={runnerWithModelExample}
  title="Runner에 기본 모델 설정"
/>

### GPT-5.x 모델

이 방식으로 [`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2) 같은 GPT-5.x 모델을 사용할 때, SDK는 기본 `modelSettings`를 적용합니다. 대부분의 사용 사례에 가장 잘 맞는 설정을 사용합니다. 기본 모델의 추론 강도를 조정하려면, 직접 `modelSettings`를 전달하세요:

<Code
  lang="typescript"
  code={gpt5DefaultModelSettingsExample}
  title="GPT-5 기본 설정 커스터마이즈"
/>

더 낮은 지연 시간을 위해 `gpt-5.2`에서는 `reasoning.effort: "none"` 사용을 권장합니다. gpt-4.1 패밀리(미니 및 나노 변형 포함) 또한 인터랙티브한 에이전트 앱을 구축하는 데 훌륭한 선택입니다.

### Non-GPT-5 모델

커스텀 `modelSettings` 없이 Non–GPT-5 모델 이름을 전달하면, SDK는 모든 모델과 호환되는 일반적인 `modelSettings`로 되돌립니다.

---

## OpenAI 프로바이더

기본 `ModelProvider`는 OpenAI API를 사용하여 이름을 해석합니다. 두 가지 구분되는 엔드포인트를 지원합니다:

| API              | 사용                                                  | `setOpenAIAPI()` 호출                  |
| ---------------- | ----------------------------------------------------- | -------------------------------------- |
| Chat Completions | 표준 챗 및 함수 호출                                  | `setOpenAIAPI('chat_completions')`     |
| Responses        | 스트리밍 우선의 새로운 생성 API(툴 호출, 유연한 출력) | `setOpenAIAPI('responses')` _(기본값)_ |

### 인증

<Code
  lang="typescript"
  code={setDefaultOpenAIKeyExample}
  title="기본 OpenAI 키 설정"
/>

맞춤 네트워킹 설정이 필요하면 `setDefaultOpenAIClient(client)`를 통해 직접 `OpenAI` 클라이언트를 연결할 수도 있습니다.

### Responses WebSocket 전송

OpenAI 프로바이더를 Responses API와 함께 사용할 때, 기본 HTTP 전송 대신 WebSocket 전송을 통해 요청을 보낼 수 있습니다.

전역으로 `setOpenAIResponsesTransport('websocket')`로 활성화하거나, 프로바이더별로 `new OpenAIProvider({ useResponses: true, useResponsesWebSocket: true })`로 활성화하세요.

WebSocket 전송만 사용하려면 `withResponsesWebSocketSession(...)` 또는 커스텀 `OpenAIProvider`가 필요하지 않습니다. 각 실행/요청마다 재연결이 허용된다면, `setOpenAIResponsesTransport('websocket')` 활성화 후에도 기존의 `run()` / `Runner.run()` 사용은 그대로 동작합니다.

연결 재사용을 최적화하고 WebSocket 프로바이더 수명 주기를 보다 명시적으로 관리하려는 경우에만 `withResponsesWebSocketSession(...)` 또는 커스텀 `OpenAIProvider` / `Runner`를 사용하세요:

- `withResponsesWebSocketSession(...)`: 콜백 이후 자동 정리가 포함된 편리한 범위 지정 수명 주기
- 커스텀 `OpenAIProvider` / `Runner`: 자체 앱 아키텍처에서의 명시적 수명 주기 제어(종료 시 정리 포함)

이름과 달리, `withResponsesWebSocketSession(...)`는 전송 수명 주기 헬퍼이며 [세션 가이드](/openai-agents-js/ko/guides/sessions)에 설명된 메모리 `Session` 인터페이스와는 관련이 없습니다.

웹소켓 프록시나 게이트웨이를 사용하는 경우, `OpenAIProvider`에서 `websocketBaseURL`을 구성하거나 `OPENAI_WEBSOCKET_BASE_URL`을 설정하세요.

Responses WebSocket 전송을 사용하는 전체 스트리밍 + HITL 예시는 [`examples/basic/stream-ws.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/basic/stream-ws.ts)를 참고하세요.

---

## ModelSettings

`ModelSettings`는 OpenAI 매개변수를 반영하지만 프로바이더에 구애받지 않습니다.

| 필드                   | 타입                                                            | 비고                                                                     |
| ---------------------- | --------------------------------------------------------------- | ------------------------------------------------------------------------ |
| `temperature`          | `number`                                                        | 창의성 대 결정성                                                         |
| `topP`                 | `number`                                                        | 누클리어스 샘플링                                                        |
| `frequencyPenalty`     | `number`                                                        | 반복 토큰 패널티                                                         |
| `presencePenalty`      | `number`                                                        | 새로운 토큰 장려                                                         |
| `toolChoice`           | `'auto' \| 'required' \| 'none' \| string`                      | [툴 사용 강제](/openai-agents-js/ko/guides/agents#forcing-tool-use) 참조 |
| `parallelToolCalls`    | `boolean`                                                       | 지원되는 경우 병렬 함수 호출 허용                                        |
| `truncation`           | `'auto' \| 'disabled'`                                          | 토큰 절단 전략                                                           |
| `maxTokens`            | `number`                                                        | 응답의 최대 토큰 수                                                      |
| `store`                | `boolean`                                                       | 응답을 보존하여 검색 / RAG 워크플로에 사용                               |
| `promptCacheRetention` | `'in-memory' \| '24h' \| null`                                  | 지원되는 경우 프로바이더 프롬프트 캐시 보존 제어                         |
| `reasoning.effort`     | `'none' \| 'minimal' \| 'low' \| 'medium' \| 'high' \| 'xhigh'` | gpt-5.x 모델의 추론 강도                                                 |
| `reasoning.summary`    | `'auto' \| 'concise' \| 'detailed'`                             | 모델이 반환하는 추론 요약의 양 제어                                      |
| `text.verbosity`       | `'low' \| 'medium' \| 'high'`                                   | gpt-5.x 등의 텍스트 장황도                                               |
| `providerData`         | `Record<string, any>`                                           | 하위 모델로 전달되는 프로바이더별 패스스루 옵션                          |

설정은 어느 레벨에나 연결할 수 있습니다:

<Code lang="typescript" code={modelSettingsExample} title="모델 설정" />

`Runner` 레벨의 설정은 에이전트별 설정과 충돌할 경우 이를 재정의합니다.

---

## 프롬프트

에이전트는 `prompt` 매개변수로 구성할 수 있으며, 이는 서버에 저장된 프롬프트 구성을 가리키며 에이전트의 동작을 제어하는 데 사용됩니다. 현재 이 옵션은 OpenAI [Responses API](https://platform.openai.com/docs/api-reference/responses)를 사용할 때만 지원됩니다.

| 필드        | 타입     | 비고                                                                                                        |
| ----------- | -------- | ----------------------------------------------------------------------------------------------------------- |
| `promptId`  | `string` | 프롬프트의 고유 식별자                                                                                      |
| `version`   | `string` | 사용하려는 프롬프트의 버전                                                                                  |
| `variables` | `object` | 프롬프트에 대체할 변수의 키/값 쌍. 값은 문자열 또는 텍스트, 이미지, 파일 같은 콘텐츠 입력 타입이 될 수 있음 |

<Code
  lang="typescript"
  code={promptIdExample}
  title="프롬프트가 있는 에이전트"
/>

tools나 instructions 같은 추가 에이전트 구성은 저장된 프롬프트에서 구성한 값을 재정의합니다.

---

## 커스텀 모델 프로바이더

자체 프로바이더 구현은 간단합니다 – `ModelProvider`와 `Model`을 구현하고 프로바이더를 `Runner` 생성자에 전달하세요:

<Code
  lang="typescript"
  code={modelCustomProviderExample}
  title="최소 커스텀 프로바이더"
/>

OpenAI 이외 모델을 위한 기성 어댑터가 필요하면, [AI SDK로 어떤 모델이든 사용](/openai-agents-js/ko/extensions/ai-sdk)을 참고하세요.

---

## 트레이싱 내보내기

OpenAI 프로바이더를 사용할 때 API 키를 제공하여 자동 트레이스 내보내기를 옵트인할 수 있습니다:

<Code
  lang="typescript"
  code={setTracingExportApiKeyExample}
  title="트레이싱 내보내기"
/>

이는 [OpenAI 대시보드](https://platform.openai.com/traces)로 트레이스를 전송하며, 거기에서 워크플로의 전체 실행 그래프를 검사할 수 있습니다.

---

## 다음 단계

- [에이전트 실행](/openai-agents-js/ko/guides/running-agents)을 살펴보세요
- [도구](/openai-agents-js/ko/guides/tools)로 모델에 강력한 기능을 부여하세요
- 필요에 따라 [가드레일](/openai-agents-js/ko/guides/guardrails) 또는 [트레이싱](/openai-agents-js/ko/guides/tracing)을 추가하세요
