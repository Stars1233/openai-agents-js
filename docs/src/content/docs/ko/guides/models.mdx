---
title: 모델
description: Choose and configure language models for your agents
---

import { Code } from '@astrojs/starlight/components';
import modelCustomProviderExample from '../../../../../../examples/docs/models/customProviders.ts?raw';
import setDefaultOpenAIKeyExample from '../../../../../../examples/docs/config/setDefaultOpenAIKey.ts?raw';
import modelSettingsExample from '../../../../../../examples/docs/models/modelSettings.ts?raw';
import promptIdExample from '../../../../../../examples/basic/prompt-id.ts?raw';
import agentWithModelExample from '../../../../../../examples/docs/models/agentWithModel.ts?raw';
import runnerWithModelExample from '../../../../../../examples/docs/models/runnerWithModel.ts?raw';
import gpt5DefaultModelSettingsExample from '../../../../../../examples/docs/models/gpt5DefaultModelSettings.ts?raw';
import setDefaultModelProviderExample from '../../../../../../examples/docs/models/setDefaultModelProvider.ts?raw';
import setTracingExportApiKeyExample from '../../../../../../examples/docs/config/setTracingExportApiKey.ts?raw';

모든 에이전트는 결국 LLM 을 호출합니다. SDK 는 모델을 두 가지 경량 인터페이스 뒤로 추상화합니다:

- [`Model`](/openai-agents-js/openai/agents/interfaces/model) – 특정 API 에 대해 _한 번의_ 요청을 수행하는 방법을 알고 있습니다
- [`ModelProvider`](/openai-agents-js/openai/agents/interfaces/modelprovider) – 사람이 읽기 쉬운 모델 **이름**(예: `'gpt‑5.2'`)을 `Model` 인스턴스로 확인(resolve)합니다

일상적인 작업에서는 보통 모델 **이름**과 가끔 `ModelSettings` 만 다루면 됩니다.

<Code
  lang="typescript"
  code={agentWithModelExample}
  title="에이전트별 모델 지정"
/>

## 모델 선택

### 기본 모델

`Agent` 를 초기화할 때 모델을 지정하지 않으면 기본 모델이 사용됩니다. 현재 기본값은 호환성과 낮은 지연 시간을 위해 [`gpt-4.1`](https://platform.openai.com/docs/models/gpt-4.1)입니다. 접근 권한이 있다면, 명시적인 `modelSettings` 를 유지하면서 더 높은 품질을 위해 에이전트를 [`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2)로 설정하는 것을 권장합니다.

[`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2) 같은 다른 모델로 전환하려면, 에이전트를 구성하는 방법이 두 가지 있습니다.

먼저, 커스텀 모델을 설정하지 않은 모든 에이전트에서 특정 모델을 일관되게 사용하려면 에이전트를 실행하기 전에 `OPENAI_DEFAULT_MODEL` 환경 변수를 설정하세요.

```bash
export OPENAI_DEFAULT_MODEL=gpt-5.2
node my-awesome-agent.js
```

둘째, `Runner` 인스턴스에 기본 모델을 설정할 수 있습니다. 에이전트에 모델을 설정하지 않으면 이 `Runner` 의 기본 모델이 사용됩니다.

<Code
  lang="typescript"
  code={runnerWithModelExample}
  title="Runner 의 기본 모델 설정"
/>

#### GPT-5.x 모델

이 방식으로 [`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2) 같은 GPT-5.x 모델을 사용하면 SDK 가 기본 `modelSettings` 를 적용합니다. 대부분의 사용 사례에서 가장 잘 동작하는 값으로 설정됩니다. 기본 모델의 추론 강도를 조정하려면 직접 `modelSettings` 를 전달하세요:

<Code
  lang="typescript"
  code={gpt5DefaultModelSettingsExample}
  title="GPT-5 기본 설정 사용자 지정"
/>

더 낮은 지연 시간을 위해 `gpt-5.2` 에서 `reasoning.effort: "none"` 사용을 권장합니다. gpt-4.1 계열( mini 및 nano 변형 포함)도 인터랙티브 에이전트 앱 구축에 여전히 좋은 선택입니다.

#### Non-GPT-5 모델

커스텀 `modelSettings` 없이 Non-GPT-5 모델 이름을 전달하면 SDK 는 모든 모델과 호환되는 일반 `modelSettings` 로 되돌아갑니다.

---

## OpenAI provider 구성

### OpenAI provider

기본 `ModelProvider` 는 OpenAI API 를 사용해 이름을 확인합니다. 서로 구분되는 두 가지
엔드포인트를 지원합니다:

| API              | 사용 방식                                              | `setOpenAIAPI()` 호출                  |
| ---------------- | ------------------------------------------------------ | -------------------------------------- |
| Chat Completions | 표준 채팅 및 함수 호출                                 | `setOpenAIAPI('chat_completions')`     |
| Responses        | 새로운 스트리밍 우선 생성 API (도구 호출, 유연한 출력) | `setOpenAIAPI('responses')` _(기본값)_ |

#### 인증

<Code
  lang="typescript"
  code={setDefaultOpenAIKeyExample}
  title="기본 OpenAI 키 설정"
/>

커스텀 네트워킹 설정이 필요하면 `setDefaultOpenAIClient(client)` 를 통해 자체 `OpenAI` 클라이언트를 연결할 수도 있습니다.

#### Responses WebSocket 전송

Responses API 와 함께 OpenAI provider 를 사용할 때, 기본 HTTP 전송 대신 WebSocket 전송으로 요청을 보낼 수 있습니다.

`setOpenAIResponsesTransport('websocket')` 로 전역 활성화하거나, `new OpenAIProvider({ useResponses: true, useResponsesWebSocket: true })` 로 provider 별로 활성화하세요.

WebSocket 전송만 사용하려면 `withResponsesWebSocketSession(...)` 이나 커스텀 `OpenAIProvider` 가 필요하지 않습니다. 각 실행/요청마다 재연결해도 괜찮다면 `setOpenAIResponsesTransport('websocket')` 활성화 후에도 기존 `run()` / `Runner.run()` 사용이 계속 동작합니다.

연결 재사용을 최적화하고 websocket provider 생명주기를 더 명시적으로 관리하려는 경우에만 `withResponsesWebSocketSession(...)` 또는 커스텀 `OpenAIProvider` / `Runner` 를 사용하세요:

- `withResponsesWebSocketSession(...)`: 콜백 이후 자동 정리되는 편리한 범위 기반 생명주기
- 커스텀 `OpenAIProvider` / `Runner`: 자체 앱 아키텍처에서 명시적 생명주기 제어(종료 시 정리 포함)

이름과 달리 `withResponsesWebSocketSession(...)` 는 전송 생명주기 헬퍼이며, [세션 가이드](/openai-agents-js/ko/guides/sessions)에서 설명하는 메모리 `Session` 인터페이스와는 관련이 없습니다.

websocket 프록시나 게이트웨이를 사용한다면 `OpenAIProvider` 의 `websocketBaseURL` 을 구성하거나 `OPENAI_WEBSOCKET_BASE_URL` 을 설정하세요.

`OpenAIProvider` 를 직접 인스턴스화한다면, websocket 기반 Responses 모델 래퍼가 연결 재사용을 위해 기본적으로 캐시된다는 점을 기억하세요. 종료 중에는 `await provider.close()` 를 호출해 해당 캐시 연결을 해제하세요. `withResponsesWebSocketSession(...)` 는 주로 이 생명주기를 대신 관리하기 위해 존재합니다. websocket 활성화 provider 와 runner 를 만들고 콜백에 전달한 뒤, 이후 항상 provider 를 닫습니다. 임시 provider 에는 `providerOptions` 를, 콜백 범위 runner 기본값에는 `runnerConfig` 를 사용하세요.

Responses WebSocket 전송을 사용하는 전체 스트리밍 + HITL 예제는 [`examples/basic/stream-ws.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/basic/stream-ws.ts)를 참고하세요.

---

## 모델 동작 및 프롬프트

### ModelSettings

`ModelSettings` 는 OpenAI 매개변수를 반영하지만 provider 에 독립적입니다.

| 필드                   | 타입                                                            | 참고                                                                       |
| ---------------------- | --------------------------------------------------------------- | -------------------------------------------------------------------------- |
| `temperature`          | `number`                                                        | 창의성과 결정성 간 균형                                                    |
| `topP`                 | `number`                                                        | 뉴클리어스 샘플링                                                          |
| `frequencyPenalty`     | `number`                                                        | 반복 토큰에 페널티 부여                                                    |
| `presencePenalty`      | `number`                                                        | 새로운 토큰 생성 장려                                                      |
| `toolChoice`           | `'auto' \| 'required' \| 'none' \| string`                      | [도구 사용 강제](/openai-agents-js/ko/guides/agents#forcing-tool-use) 참고 |
| `parallelToolCalls`    | `boolean`                                                       | 지원되는 경우 병렬 함수 호출 허용                                          |
| `truncation`           | `'auto' \| 'disabled'`                                          | 토큰 잘림 전략                                                             |
| `maxTokens`            | `number`                                                        | 응답의 최대 토큰 수                                                        |
| `store`                | `boolean`                                                       | 검색 / RAG 워크플로를 위해 응답 저장                                       |
| `promptCacheRetention` | `'in-memory' \| '24h' \| null`                                  | 지원되는 경우 provider 프롬프트 캐시 보존 제어                             |
| `reasoning.effort`     | `'none' \| 'minimal' \| 'low' \| 'medium' \| 'high' \| 'xhigh'` | gpt-5.x 모델의 추론 강도                                                   |
| `reasoning.summary`    | `'auto' \| 'concise' \| 'detailed'`                             | 모델이 반환하는 추론 요약의 양 제어                                        |
| `text.verbosity`       | `'low' \| 'medium' \| 'high'`                                   | gpt-5.x 등의 텍스트 장황도                                                 |
| `providerData`         | `Record<string, any>`                                           | 하위 모델로 전달되는 provider 전용 패스스루 옵션                           |

설정은 두 수준 중 어느 쪽에도 연결할 수 있습니다:

<Code lang="typescript" code={modelSettingsExample} title="모델 설정" />

`Runner` 수준 설정은 충돌하는 에이전트별 설정을 재정의합니다.

---

### 프롬프트

에이전트는 `prompt` 매개변수로 구성할 수 있으며, 이는 에이전트 동작 제어에 사용할 서버 저장 프롬프트 구성을 나타냅니다. 현재 이 옵션은 OpenAI [Responses API](https://platform.openai.com/docs/api-reference/responses)를 사용할 때만 지원됩니다.

| 필드        | 타입     | 참고                                                                                                         |
| ----------- | -------- | ------------------------------------------------------------------------------------------------------------ |
| `promptId`  | `string` | 프롬프트의 고유 식별자                                                                                       |
| `version`   | `string` | 사용하려는 프롬프트 버전                                                                                     |
| `variables` | `object` | 프롬프트에 치환할 변수의 키/값 쌍. 값은 문자열 또는 텍스트, 이미지, 파일 같은 콘텐츠 입력 타입일 수 있습니다 |

<Code
  lang="typescript"
  code={promptIdExample}
  title="프롬프트가 있는 에이전트"
/>

tools 나 instructions 같은 추가 에이전트 구성은, 저장된 프롬프트에 구성된 값을 재정의합니다.

---

## 고급 provider 및 가시성

### 커스텀 모델 provider

자체 provider 구현은 간단합니다. `ModelProvider` 와 `Model` 을 구현하고 provider 를 `Runner` 생성자에 전달하세요:

<Code
  lang="typescript"
  code={modelCustomProviderExample}
  title="최소 커스텀 provider"
/>

모든 `run()` 호출과 새로 생성되는 모든 `Runner` 가 기본적으로 동일한 provider 를 사용하게 하려면, 앱 시작 시 한 번만 설정하세요:

<Code
  lang="typescript"
  code={setDefaultModelProviderExample}
  title="기본 모델 provider 설정"
/>

이 방법은 앱이 Non-OpenAI provider 를 표준으로 사용하고, 어디서나 커스텀 `Runner` 를 전달하고 싶지 않을 때 유용합니다.

Non-OpenAI 모델용 기성 어댑터가 필요하다면 [AI SDK로 어떤 모델이든 사용](/openai-agents-js/ko/extensions/ai-sdk)을 참고하세요.

---

### 트레이싱 자격 증명

지원되는 서버 런타임에서는 트레이싱이 이미 기본 활성화되어 있습니다. 트레이스 내보내기에 기본 OpenAI API 키와 다른 자격 증명을 사용해야 할 때만 `setTracingExportApiKey()` 를 사용하세요:

<Code
  lang="typescript"
  code={setTracingExportApiKeyExample}
  title="트레이싱 내보내기 API 키 설정"
/>

이렇게 하면 해당 자격 증명으로 [OpenAI dashboard](https://platform.openai.com/traces)에 트레이스를 전송합니다. 커스텀 수집 엔드포인트나 재시도 튜닝 같은 exporter 사용자 지정은 [트레이싱 가이드](/openai-agents-js/ko/guides/tracing#openai-tracing-exporter)를 참고하세요.

---

## 다음 단계

- [에이전트 실행](/openai-agents-js/ko/guides/running-agents)을 살펴보세요
- [도구](/openai-agents-js/ko/guides/tools)로 모델에 강력한 기능을 추가하세요
- 필요에 따라 [가드레일](/openai-agents-js/ko/guides/guardrails) 또는 [트레이싱](/openai-agents-js/ko/guides/tracing)을 추가하세요
