---
title: 모델
description: Choose and configure language models for your agents
---

import { Code } from '@astrojs/starlight/components';
import modelCustomProviderExample from '../../../../../../examples/docs/models/customProviders.ts?raw';
import setDefaultOpenAIKeyExample from '../../../../../../examples/docs/config/setDefaultOpenAIKey.ts?raw';
import modelSettingsExample from '../../../../../../examples/docs/models/modelSettings.ts?raw';
import promptIdExample from '../../../../../../examples/basic/prompt-id.ts?raw';
import agentWithModelExample from '../../../../../../examples/docs/models/agentWithModel.ts?raw';
import runnerWithModelExample from '../../../../../../examples/docs/models/runnerWithModel.ts?raw';
import gpt5DefaultModelSettingsExample from '../../../../../../examples/docs/models/gpt5DefaultModelSettings.ts?raw';
import setDefaultModelProviderExample from '../../../../../../examples/docs/models/setDefaultModelProvider.ts?raw';
import setTracingExportApiKeyExample from '../../../../../../examples/docs/config/setTracingExportApiKey.ts?raw';

모든 에이전트는 궁극적으로 LLM을 호출합니다. SDK는 모델을 두 가지 경량 인터페이스로 추상화합니다:

- [`Model`](/openai-agents-js/openai/agents/interfaces/model) – 특정 API에 대해 _한 번의_ 요청을 수행하는 방법을 알고 있습니다
- [`ModelProvider`](/openai-agents-js/openai/agents/interfaces/modelprovider) – 사람이 읽기 쉬운 모델 **이름**(예: `'gpt‑5.2'`)을 `Model` 인스턴스로 해석합니다

일상적인 작업에서는 보통 모델 **이름**만 다루고, 가끔 `ModelSettings`를 다루게 됩니다.

<Code
  lang="typescript"
  code={agentWithModelExample}
  title="에이전트별 모델 지정"
/>

## 모델 선택

### 기본 모델

`Agent`를 초기화할 때 모델을 지정하지 않으면 기본 모델이 사용됩니다. 현재 기본값은 호환성과 낮은 지연 시간을 위해 [`gpt-4.1`](https://platform.openai.com/docs/models/gpt-4.1)입니다. 접근 권한이 있다면, 명시적인 `modelSettings`를 유지하면서 더 높은 품질을 위해 에이전트를 [`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2)로 설정하는 것을 권장합니다.

[`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2) 같은 다른 모델로 전환하려면, 에이전트를 구성하는 방법이 두 가지 있습니다.

첫째, 커스텀 모델을 설정하지 않은 모든 에이전트에서 일관되게 특정 모델을 사용하려면 에이전트를 실행하기 전에 `OPENAI_DEFAULT_MODEL` 환경 변수를 설정하세요.

```bash
export OPENAI_DEFAULT_MODEL=gpt-5.2
node my-awesome-agent.js
```

둘째, `Runner` 인스턴스에 기본 모델을 설정할 수 있습니다. 에이전트에 모델을 설정하지 않으면 이 `Runner`의 기본 모델이 사용됩니다.

<Code
  lang="typescript"
  code={runnerWithModelExample}
  title="Runner의 기본 모델 설정"
/>

#### GPT-5.x 모델

이 방식으로 [`gpt-5.2`](https://platform.openai.com/docs/models/gpt-5.2) 같은 GPT-5.x 모델을 사용하면, SDK가 기본 `modelSettings`를 적용합니다. 대부분의 사용 사례에서 가장 잘 동작하는 값으로 설정됩니다. 기본 모델의 추론 강도를 조정하려면 자체 `modelSettings`를 전달하세요:

<Code
  lang="typescript"
  code={gpt5DefaultModelSettingsExample}
  title="GPT-5 기본 설정 사용자 지정"
/>

더 낮은 지연 시간을 원한다면, `gpt-5.2`에서 `reasoning.effort: "none"` 사용을 권장합니다. gpt-4.1 계열(미니 및 나노 변형 포함)도 인터랙티브 에이전트 앱 구축에 여전히 좋은 선택입니다.

#### GPT-5가 아닌 모델

커스텀 `modelSettings` 없이 GPT-5가 아닌 모델 이름을 전달하면, SDK는 모든 모델과 호환되는 일반 `modelSettings`로 되돌아갑니다.

---

## OpenAI provider 구성

### OpenAI provider

기본 `ModelProvider`는 OpenAI API를 사용해 이름을 해석합니다. 두 가지 서로 다른 엔드포인트를 지원합니다:

| API              | 사용 방식                                             | `setOpenAIAPI()` 호출                  |
| ---------------- | ----------------------------------------------------- | -------------------------------------- |
| Chat Completions | 표준 채팅 및 함수 호출                                | `setOpenAIAPI('chat_completions')`     |
| Responses        | 새로운 스트리밍 우선 생성 API(도구 호출, 유연한 출력) | `setOpenAIAPI('responses')` _(기본값)_ |

#### 인증

<Code
  lang="typescript"
  code={setDefaultOpenAIKeyExample}
  title="기본 OpenAI 키 설정"
/>

커스텀 네트워킹 설정이 필요하면 `setDefaultOpenAIClient(client)`를 통해 자체 `OpenAI` 클라이언트를 연결할 수도 있습니다.

#### Responses WebSocket 전송

OpenAI provider를 Responses API와 함께 사용할 때, 기본 HTTP 전송 대신 WebSocket 전송으로 요청을 보낼 수 있습니다.

`setOpenAIResponsesTransport('websocket')`으로 전역 활성화하거나, `new OpenAIProvider({ useResponses: true, useResponsesWebSocket: true })`로 provider별 활성화가 가능합니다.

WebSocket 전송만 사용하려면 `withResponsesWebSocketSession(...)`이나 커스텀 `OpenAIProvider`가 필요하지 않습니다. 각 실행/요청마다 재연결해도 괜찮다면, `setOpenAIResponsesTransport('websocket')`을 활성화한 뒤에도 기존 `run()` / `Runner.run()` 사용 방식이 계속 동작합니다.

전송 방식 선택은 모델 해석을 따릅니다:

- `setOpenAIResponsesTransport('websocket')`은 Responses API 사용 중 OpenAI provider를 통해 나중에 해석되는 문자열 모델 이름에만 영향을 줍니다
- `Agent`나 `Runner`에 구체적인 `Model` 인스턴스를 전달하면 해당 인스턴스가 그대로 사용됩니다. `OpenAIResponsesWSModel`은 WebSocket, `OpenAIResponsesModel`은 HTTP, `OpenAIChatCompletionsModel`은 Chat Completions를 유지합니다
- 자체 `modelProvider`를 제공하면 그 provider가 모델 해석을 제어합니다. 이 경우 전역 설정자에 의존하지 말고 해당 provider에서 WebSocket을 활성화하세요
- 프록시, 게이트웨이 또는 기타 OpenAI 호환 엔드포인트를 경유한다면 대상이 WebSocket `/responses` 엔드포인트를 지원해야 합니다. 또한 `websocketBaseURL`을 명시적으로 설정해야 할 수 있습니다

연결 재사용을 최적화하고 websocket provider 수명 주기를 더 명시적으로 관리하려는 경우에만 `withResponsesWebSocketSession(...)` 또는 커스텀 `OpenAIProvider` / `Runner`를 사용하세요:

- `withResponsesWebSocketSession(...)`: 콜백 이후 자동 정리를 포함한 편리한 범위형 수명 주기
- 커스텀 `OpenAIProvider` / `Runner`: 앱 아키텍처 내에서 명시적인 수명 주기 제어(종료 시 정리 포함)

이름과 달리 `withResponsesWebSocketSession(...)`은 전송 수명 주기 헬퍼이며, [세션 가이드](/openai-agents-js/ko/guides/sessions)에 설명된 메모리 `Session` 인터페이스와는 무관합니다.

websocket 프록시 또는 게이트웨이를 사용하는 경우 `OpenAIProvider`에서 `websocketBaseURL`을 구성하거나 `OPENAI_WEBSOCKET_BASE_URL`을 설정하세요.

`OpenAIProvider`를 직접 인스턴스화하는 경우, websocket 기반 Responses 모델 래퍼는 연결 재사용을 위해 기본적으로 캐시된다는 점을 기억하세요. 종료 시 캐시된 연결을 해제하려면 `await provider.close()`를 호출하세요. `withResponsesWebSocketSession(...)`은 주로 이 수명 주기를 관리하기 위해 존재합니다. websocket 활성화 provider와 runner를 생성해 콜백에 전달하고, 이후 항상 provider를 닫습니다. 임시 provider에는 `providerOptions`, 콜백 범위 runner 기본값에는 `runnerConfig`를 사용하세요.

Responses WebSocket 전송을 사용하는 전체 스트리밍 + HITL 예시는 [`examples/basic/stream-ws.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/basic/stream-ws.ts)를 참고하세요.

---

## 모델 동작 및 프롬프트

### ModelSettings

`ModelSettings`는 OpenAI 매개변수를 반영하지만 provider에 종속되지 않습니다.

| 필드                   | 타입                                                            | 참고                                                                       |
| ---------------------- | --------------------------------------------------------------- | -------------------------------------------------------------------------- |
| `temperature`          | `number`                                                        | 창의성과 결정성의 균형                                                     |
| `topP`                 | `number`                                                        | 뉴클리어스 샘플링                                                          |
| `frequencyPenalty`     | `number`                                                        | 반복 토큰에 페널티 부여                                                    |
| `presencePenalty`      | `number`                                                        | 새로운 토큰 유도                                                           |
| `toolChoice`           | `'auto' \| 'required' \| 'none' \| string`                      | [도구 사용 강제](/openai-agents-js/ko/guides/agents#forcing-tool-use) 참고 |
| `parallelToolCalls`    | `boolean`                                                       | 지원되는 경우 병렬 함수 호출 허용                                          |
| `truncation`           | `'auto' \| 'disabled'`                                          | 토큰 잘림 전략                                                             |
| `maxTokens`            | `number`                                                        | 응답의 최대 토큰 수                                                        |
| `store`                | `boolean`                                                       | 검색/RAG 워크플로를 위해 응답 영구 저장                                    |
| `promptCacheRetention` | `'in-memory' \| '24h' \| null`                                  | 지원되는 경우 provider 프롬프트 캐시 보존 기간 제어                        |
| `reasoning.effort`     | `'none' \| 'minimal' \| 'low' \| 'medium' \| 'high' \| 'xhigh'` | gpt-5.x 모델의 추론 강도                                                   |
| `reasoning.summary`    | `'auto' \| 'concise' \| 'detailed'`                             | 모델이 반환하는 추론 요약량 제어                                           |
| `text.verbosity`       | `'low' \| 'medium' \| 'high'`                                   | gpt-5.x 등의 텍스트 상세도                                                 |
| `providerData`         | `Record<string, any>`                                           | 하위 모델로 전달되는 provider 전용 패스스루 옵션                           |

설정은 두 수준 중 어느 쪽이든 적용할 수 있습니다:

<Code lang="typescript" code={modelSettingsExample} title="모델 설정" />

`Runner` 수준 설정은 충돌하는 에이전트별 설정을 덮어씁니다.

---

### 프롬프트

에이전트는 `prompt` 매개변수로 구성할 수 있으며, 이는 에이전트 동작을 제어하기 위해 서버에 저장된 프롬프트 구성을 사용함을 의미합니다. 현재 이 옵션은 OpenAI [Responses API](https://platform.openai.com/docs/api-reference/responses)를 사용할 때만 지원됩니다.

| 필드        | 타입     | 참고                                                                                                          |
| ----------- | -------- | ------------------------------------------------------------------------------------------------------------- |
| `promptId`  | `string` | 프롬프트의 고유 식별자                                                                                        |
| `version`   | `string` | 사용하려는 프롬프트 버전                                                                                      |
| `variables` | `object` | 프롬프트에 치환할 변수의 키/값 쌍. 값은 문자열이거나 텍스트, 이미지, 파일 같은 콘텐츠 입력 타입일 수 있습니다 |

<Code
  lang="typescript"
  code={promptIdExample}
  title="프롬프트가 있는 에이전트"
/>

도구나 instructions 같은 추가 에이전트 구성은 저장된 프롬프트에 설정한 값을 덮어씁니다.

---

## 고급 provider 및 관측 가능성

### 커스텀 모델 provider

자체 provider 구현은 간단합니다. `ModelProvider`와 `Model`을 구현하고, 해당 provider를 `Runner` 생성자에 전달하면 됩니다:

<Code
  lang="typescript"
  code={modelCustomProviderExample}
  title="최소 커스텀 provider"
/>

모든 `run()` 호출과 새로 생성되는 모든 `Runner`가 기본적으로 같은 provider를 사용하게 하려면, 앱 시작 시 한 번만 설정하세요:

<Code
  lang="typescript"
  code={setDefaultModelProviderExample}
  title="기본 모델 provider 설정"
/>

이 방법은 앱이 OpenAI가 아닌 provider를 표준으로 사용하고, 어디서나 커스텀 `Runner`를 전달하고 싶지 않을 때 유용합니다.

OpenAI가 아닌 모델을 위한 준비된 어댑터가 필요하면 [AI SDK로 어떤 모델이든 사용](/openai-agents-js/ko/extensions/ai-sdk)을 참고하세요.

---

### 트레이싱 자격 증명

지원되는 서버 런타임에서는 트레이싱이 기본적으로 이미 활성화되어 있습니다. trace 내보내기에 기본 OpenAI API 키와 다른 자격 증명을 사용해야 할 때만 `setTracingExportApiKey()`를 사용하세요:

<Code
  lang="typescript"
  code={setTracingExportApiKeyExample}
  title="트레이싱 내보내기 API 키 설정"
/>

이렇게 하면 해당 자격 증명으로 [OpenAI 대시보드](https://platform.openai.com/traces)로 trace가 전송됩니다. 커스텀 수집 엔드포인트나 재시도 튜닝 같은 exporter 사용자 지정은 [트레이싱 가이드](/openai-agents-js/ko/guides/tracing#openai-tracing-exporter)를 참고하세요.

---

## 다음 단계

- [에이전트 실행](/openai-agents-js/ko/guides/running-agents)을 살펴보세요
- [도구](/openai-agents-js/ko/guides/tools)로 모델에 강력한 기능을 추가하세요
- 필요에 따라 [가드레일](/openai-agents-js/ko/guides/guardrails) 또는 [트레이싱](/openai-agents-js/ko/guides/tracing)을 추가하세요
