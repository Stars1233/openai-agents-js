---
title: 음성 에이전트 구축
description: Learn how to build voice agents using the OpenAI Agents SDK, what features are available, how to architecture your application, and more.
---

import { Steps, Aside, Code } from '@astrojs/starlight/components';
import createAgentExample from '../../../../../../../examples/docs/voice-agents/createAgent.ts?raw';
import multiAgentsExample from '../../../../../../../examples/docs/voice-agents/multiAgents.ts?raw';
import createSessionExample from '../../../../../../../examples/docs/voice-agents/createSession.ts?raw';
import configureSessionExample from '../../../../../../../examples/docs/voice-agents/configureSession.ts?raw';
import handleAudioExample from '../../../../../../../examples/docs/voice-agents/handleAudio.ts?raw';
import defineToolExample from '../../../../../../../examples/docs/voice-agents/defineTool.ts?raw';
import toolApprovalEventExample from '../../../../../../../examples/docs/voice-agents/toolApprovalEvent.ts?raw';
import guardrailsExample from '../../../../../../../examples/docs/voice-agents/guardrails.ts?raw';
import guardrailSettingsExample from '../../../../../../../examples/docs/voice-agents/guardrailSettings.ts?raw';
import audioInterruptedExample from '../../../../../../../examples/docs/voice-agents/audioInterrupted.ts?raw';
import sessionInterruptExample from '../../../../../../../examples/docs/voice-agents/sessionInterrupt.ts?raw';
import sessionHistoryExample from '../../../../../../../examples/docs/voice-agents/sessionHistory.ts?raw';
import historyUpdatedExample from '../../../../../../../examples/docs/voice-agents/historyUpdated.ts?raw';
import updateHistoryExample from '../../../../../../../examples/docs/voice-agents/updateHistory.ts?raw';
import customWebRTCTransportExample from '../../../../../../../examples/docs/voice-agents/customWebRTCTransport.ts?raw';
import websocketSessionExample from '../../../../../../../examples/docs/voice-agents/websocketSession.ts?raw';
import transportEventsExample from '../../../../../../../examples/docs/voice-agents/transportEvents.ts?raw';
import thinClientExample from '../../../../../../../examples/docs/voice-agents/thinClient.ts?raw';
import toolHistoryExample from '../../../../../../../examples/docs/voice-agents/toolHistory.ts?raw';
import sendMessageExample from '../../../../../../../examples/docs/voice-agents/sendMessage.ts?raw';
import serverAgentExample from '../../../../../../../examples/docs/voice-agents/serverAgent.ts?raw';
import delegationAgentExample from '../../../../../../../examples/docs/voice-agents/delegationAgent.ts?raw';
import turnDetectionExample from '../../../../../../../examples/docs/voice-agents/turnDetection.ts?raw';

## 세션 설정

### 오디오 처리

기본 `OpenAIRealtimeWebRTC` 같은 일부 전송 계층은 오디오 입력과 출력을 자동으로 처리합니다. `OpenAIRealtimeWebSocket` 같은 다른 전송 메커니즘을 사용하는 경우 세션 오디오를 직접 처리해야 합니다:

<Code lang="typescript" code={handleAudioExample} />

### 세션 구성

세션을 구성하려면 생성 시 [`RealtimeSession`](/openai-agents-js/openai/agents-realtime/classes/realtimesession/)에 추가 옵션을 전달하거나 `connect(...)`를 호출할 때 전달하세요.

<Code lang="typescript" code={configureSessionExample} />

이 전송 계층에서는 [세션](https://platform.openai.com/docs/api-reference/realtime-client-events/session/update)과 일치하는 모든 매개변수를 전달할 수 있습니다.

[RealtimeSessionConfig](/openai-agents-js/openai/agents-realtime/type-aliases/realtimesessionconfig/)에 아직 없는 새로운 매개변수의 경우 `providerData`를 사용할 수 있습니다. `providerData`에 전달한 내용은 `session` 객체의 일부로 그대로 전달됩니다.

생성 시 설정할 수 있는 추가 `RealtimeSession` 옵션:

| Option                                        | Type                              | Purpose                                                      |
| --------------------------------------------- | --------------------------------- | ------------------------------------------------------------ |
| `context`                                     | `TContext`                        | 세션 컨텍스트에 병합되는 추가 로컬 컨텍스트                  |
| `historyStoreAudio`                           | `boolean`                         | 로컬 히스토리 스냅샷에 오디오 데이터 저장 (기본값: 비활성화) |
| `outputGuardrails`                            | `RealtimeOutputGuardrail[]`       | 세션용 출력 가드레일 (참고: [가드레일](#guardrails))         |
| `outputGuardrailSettings`                     | `RealtimeOutputGuardrailSettings` | 가드레일 검사 주기와 동작                                    |
| `tracingDisabled`                             | `boolean`                         | 세션에 대한 트레이싱 비활성화                                |
| `groupId`                                     | `string`                          | 세션 또는 백엔드 실행 전반에서 트레이스 그룹화               |
| `traceMetadata`                               | `Record<string, any>`             | 세션 트레이스에 첨부할 사용자 정의 메타데이터                |
| `workflowName`                                | `string`                          | 트레이스 워크플로의 보기 쉬운 이름                           |
| `automaticallyTriggerResponseForMcpToolCalls` | `boolean`                         | MCP 도구 호출 완료 시 모델 응답 자동 트리거 (기본값: `true`) |
| `toolErrorFormatter`                          | `ToolErrorFormatter`              | 모델에 반환되는 도구 승인 거부 메시지 커스터마이즈           |

`connect(...)` 옵션:

| Option   | Type                                          | Purpose                                    |
| -------- | --------------------------------------------- | ------------------------------------------ |
| `apiKey` | `string \| (() => string \| Promise<string>)` | 이 연결에 사용할 API 키(또는 지연 로더)    |
| `model`  | `OpenAIRealtimeModels \| string`              | 전송 연결에 대한 선택적 모델 재지정        |
| `url`    | `string`                                      | 선택적 사용자 지정 Realtime 엔드포인트 URL |
| `callId` | `string`                                      | 기존의 SIP로 시작된 통화/세션에 첨부       |

## 에이전트 기능

### 핸드오프

일반 에이전트와 유사하게, 핸드오프를 사용해 에이전트를 여러 에이전트로 분할하고 이들 간을 오케스트레이션하여 성능을 개선하고 문제 범위를 더 잘 정의할 수 있습니다.

<Code lang="typescript" code={multiAgentsExample} />

일반 에이전트와 달리, 실시간 에이전트에서는 핸드오프 동작이 약간 다릅니다. 핸드오프가 수행되면 진행 중인 세션이 새 에이전트 구성으로 업데이트됩니다. 이로 인해 에이전트는 진행 중인 대화 기록에 자동으로 접근할 수 있으며, 입력 필터는 현재 적용되지 않습니다.

또한, 이 말은 핸드오프의 일환으로 `voice` 또는 `model`을 변경할 수 없다는 뜻입니다. 다른 실시간 에이전트에만 연결할 수 있습니다. 다른 모델, 예를 들어 `gpt-5-mini` 같은 추론 모델이 필요하면 [도구를 통한 위임](#delegation-through-tools)을 사용하세요.

### 도구

일반 에이전트와 마찬가지로, 실시간 에이전트는 작업 수행을 위해 도구를 호출할 수 있습니다. Realtime은 **함수 도구**(로컬 실행)와 **호스티드 MCP 도구**(Realtime API가 원격 실행)를 지원합니다. 일반 에이전트에서 사용하던 것과 동일한 `tool()` 헬퍼로 함수 도구를 정의할 수 있습니다.

<Code lang="typescript" code={defineToolExample} />

함수 도구는 `RealtimeSession`과 동일한 환경에서 실행됩니다. 즉, 브라우저에서 세션을 실행 중이면 도구도 브라우저에서 실행됩니다. 민감한 작업이 필요하다면 도구 내부에서 백엔드로 HTTP 요청을 보내세요.

호스티드 MCP 도구는 `hostedMcpTool`로 구성하며 원격으로 실행됩니다. MCP 도구 가용성이 변경되면 세션이 `mcp_tools_changed`를 발생시킵니다. MCP 도구 호출 완료 후 세션이 자동으로 모델 응답을 트리거하지 않게 하려면 `automaticallyTriggerResponseForMcpToolCalls: false`로 설정하세요.

도구가 실행되는 동안 에이전트는 사용자의 새 요청을 처리할 수 없습니다. 경험을 개선하는 한 가지 방법은 에이전트에게 도구를 실행하기 직전임을 알리게 하거나, 도구 실행 시간을 벌기 위한 특정 문구를 말하도록 지시하는 것입니다.

함수 도구가 즉시 다른 모델 응답을 트리거하지 않고 종료되어야 한다면, `@openai/agents/realtime`의 `backgroundResult(output)`를 반환하세요.
이렇게 하면 응답 트리거는 그대로 두고 도구 출력을 세션으로 되돌려 보냅니다.

함수 도구 타임아웃 옵션(`timeoutMs`, `timeoutBehavior`, `timeoutErrorFunction`)은 실시간 세션에서도 동일하게 동작합니다. 기본값인 `error_as_result`에서는 타임아웃 메시지가 도구 출력으로 전송됩니다. `raise_exception`의 경우 세션이 [`ToolTimeoutError`](/openai-agents-js/openai/agents-core/classes/tooltimeouterror)와 함께 `error` 이벤트를 발생시키며 해당 호출에 대한 도구 출력은 전송되지 않습니다.

#### 대화 기록 접근

에이전트가 특정 도구를 호출할 때 전달된 인자 외에도, Realtime 세션이 추적하는 현재 대화 기록의 스냅샷에 접근할 수 있습니다. 이는 현재 대화 상태에 기반해 더 복잡한 작업을 수행해야 하거나 [도구를 통한 위임](#delegation-through-tools)을 사용할 계획일 때 유용합니다.

<Code lang="typescript" code={toolHistoryExample} />

<Aside type="note">
  전달되는 히스토리는 도구 호출 시점의 히스토리 스냅샷입니다. 사용자가
  마지막으로 말한 내용의 전사본은 아직 준비되지 않았을 수 있습니다.
</Aside>

#### 도구 실행 전 승인

`needsApproval: true`로 도구를 정의하면, 에이전트가 도구를 실행하기 전에 `tool_approval_requested` 이벤트를 발생시킵니다.

이 이벤트를 수신하여 사용자에게 도구 호출 승인 또는 거부 UI를 보여줄 수 있습니다.

<Code lang="typescript" code={toolApprovalEventExample} />

<Aside type="note">
  음성 에이전트가 도구 호출 승인을 기다리는 동안, 에이전트는 사용자의 새로운
  요청을 처리할 수 없습니다.
</Aside>

### 가드레일

가드레일은 에이전트의 발화가 특정 규칙을 위반했는지 모니터링하고 즉시 응답을 차단하는 방법을 제공합니다. 이러한 가드레일 검사는 에이전트 응답의 전사본(Transcript)을 기반으로 수행되므로 모델의 텍스트 출력이 활성화되어 있어야 합니다(기본값: 활성화).

제공한 가드레일은 모델 응답이 반환되는 동안 비동기적으로 실행되어, 예를 들어 "특정 금지어를 언급" 같은 사전 정의된 분류 트리거에 따라 응답을 차단할 수 있습니다.

가드레일이 발동되면 세션은 `guardrail_tripped` 이벤트를 발생시킵니다. 이벤트는 또한 가드레일을 촉발한 `itemId`를 포함하는 `details` 객체를 제공합니다.

<Code lang="typescript" code={guardrailsExample} />

기본적으로 가드레일은 100자마다 또는 응답 텍스트가 끝날 때 실행됩니다.
말하기는 보통 더 오래 걸리기 때문에, 대부분의 경우 사용자에게 들리기 전에
가드레일이 위반을 포착할 수 있습니다.

이 동작을 수정하려면 세션에 `outputGuardrailSettings` 객체를 전달하세요.

<Code lang="typescript" code={guardrailSettingsExample} />

## 상호작용 흐름

### 턴 감지 / 음성 활동 감지

Realtime 세션은 사용자가 말할 때를 자동으로 감지하고, Realtime API의 내장 [음성 활동 감지 모드](https://platform.openai.com/docs/guides/realtime-vad)를 사용해 새로운 턴을 트리거합니다.

세션에 `turnDetection` 객체를 전달해 음성 활동 감지 모드를 변경할 수 있습니다.

<Code lang="typescript" code={turnDetectionExample} />

턴 감지 설정을 수정하면 원치 않는 인터럽션 보정과 무음 처리에 도움이 됩니다. 다양한 설정에 대한 자세한 내용은 [Realtime API 문서](https://platform.openai.com/docs/guides/realtime-vad)를 확인하세요.

### 인터럽션(중단 처리)

내장 음성 활동 감지를 사용할 때, 사용자가 에이전트의 말 위로 말하면 에이전트는 자동으로 이를 감지하고 말한 내용에 따라 컨텍스트를 업데이트합니다. 또한 `audio_interrupted` 이벤트를 발생시킵니다. 이는 모든 오디오 재생을 즉시 중지하는 데 사용할 수 있습니다(웹소켓 연결에만 해당).

<Code lang="typescript" code={audioInterruptedExample} />

UI에 "중지" 버튼을 제공하는 등 수동 인터럽션을 수행하려면, `interrupt()`를 수동으로 호출할 수 있습니다:

<Code lang="typescript" code={sessionInterruptExample} />

어느 방식이든, Realtime 세션은 에이전트의 생성 중단, 사용자에게 말했던 내용의 절단, 히스토리 업데이트를 모두 처리합니다.

에이전트에 WebRTC로 연결하는 경우 오디오 출력도 지웁니다. WebSocket을 사용하는 경우 대기 중인 오디오 재생을 직접 중지해야 합니다.

### 텍스트 입력

에이전트에 텍스트 입력을 보내려면 `RealtimeSession`의 `sendMessage` 메서드를 사용하세요.

이는 사용자가 에이전트와 두 가지 모달리티로 상호작용하도록 하거나, 대화에 추가 컨텍스트를 제공하려는 경우 유용합니다.

<Code lang="typescript" code={sendMessageExample} />

## 대화 상태와 위임

### 대화 기록 관리

`RealtimeSession`은 `history` 속성에서 대화 기록을 자동으로 관리합니다:

이를 사용해 고객에게 기록을 렌더링하거나 추가 작업을 수행할 수 있습니다. 대화 진행 중에는 이 기록이 지속적으로 변경되므로 `history_updated` 이벤트를 수신할 수 있습니다.

기록을 수정하려면, 예를 들어 메시지를 완전히 제거하거나 전사본을 업데이트하려면 `updateHistory` 메서드를 사용하세요.

<Code lang="typescript" code={updateHistoryExample} />

#### 제한 사항

1. 현재로서는 사후에 함수 도구 호출을 업데이트/변경할 수 없습니다
2. 기록의 텍스트 출력에는 전사본과 텍스트 모달리티가 활성화되어 있어야 합니다
3. 인터럽션으로 잘린 응답은 전사본이 없습니다

### 도구를 통한 위임

![Delegation through tools](https://cdn.openai.com/API/docs/diagram-speech-to-speech-agent-tools.png)

대화 기록과 도구 호출을 결합하면, 더 복잡한 작업을 수행하도록 백엔드의 다른 에이전트에 대화를 위임하고, 그 결과를 사용자에게 다시 전달할 수 있습니다.

<Code lang="typescript" code={delegationAgentExample} />

아래 코드는 서버에서 실행됩니다. 이 예에서는 Next.js의 server actions를 통해 실행됩니다.

<Code lang="typescript" code={serverAgentExample} />
