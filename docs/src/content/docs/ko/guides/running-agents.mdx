---
title: 에이전트 실행
description: Configure and execute agent workflows with the Runner class
---

import { Aside, Code } from '@astrojs/starlight/components';
import helloWorldWithRunnerExample from '../../../../../../examples/docs/hello-world-with-runner.ts?raw';
import helloWorldExample from '../../../../../../examples/docs/hello-world.ts?raw';
import runningAgentsExceptionExample from '../../../../../../examples/docs/running-agents/exceptions1.ts?raw';
import chatLoopExample from '../../../../../../examples/docs/running-agents/chatLoop.ts?raw';
import conversationIdExample from '../../../../../../examples/docs/running-agents/conversationId.ts?raw';
import previousResponseIdExample from '../../../../../../examples/docs/running-agents/previousResponseId.ts?raw';

에이전트는 스스로 아무 작업도 하지 않습니다. `Runner` 클래스 또는 `run()` 유틸리티로 에이전트를 **실행**해야 합니다.

<Code lang="typescript" code={helloWorldExample} title="Simple run" />

커스텀 runner 가 필요하지 않다면, 싱글턴 기본 `Runner` 인스턴스를 실행하는 `run()` 유틸리티를 사용할 수도 있습니다.

또는 직접 runner 인스턴스를 생성할 수 있습니다:

<Code lang="typescript" code={helloWorldWithRunnerExample} title="Simple run" />

에이전트를 실행한 뒤에는 최종 출력과 실행의 전체 기록이 포함된 [실행 결과](/openai-agents-js/ko/guides/results) 객체를 받게 됩니다.

## Runner 수명 주기 및 설정

### 에이전트 루프

Runner 의 run 메서드를 사용할 때 시작 에이전트와 입력을 전달합니다. 입력은 문자열(사용자 메시지로 간주) 또는 OpenAI Responses API 의 항목인 입력 항목 목록일 수 있습니다.

그다음 runner 는 루프를 실행합니다:

1. 현재 입력으로 현재 에이전트의 모델을 호출합니다
2. LLM 응답을 검사합니다
   - **최종 출력** → 반환
   - **핸드오프** → 새 에이전트로 전환, 누적된 대화 기록 유지, 1로 이동
   - **도구 호출** → 도구 실행, 결과를 대화에 추가, 1로 이동
3. `maxTurns` 에 도달하면 [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) 를 발생시킵니다

<Aside type="note">
  LLM 출력이 "최종 출력"으로 간주되는 기준은 원하는 타입의 텍스트 출력을
  생성하고 도구 호출이 없는 경우입니다.
</Aside>

#### Runner 수명 주기

앱 시작 시 `Runner` 를 만들고 요청 전반에서 재사용하세요. 인스턴스에는 모델 provider, 트레이싱 옵션 같은 전역 설정이 저장됩니다. 완전히 다른 구성이 필요할 때만 다른 `Runner` 를 만드세요. 간단한 스크립트에서는 내부적으로 기본 runner 를 사용하는 `run()` 을 호출해도 됩니다.

### 실행 인수

`run()` 메서드 입력은 실행을 시작할 초기 에이전트, 실행 입력, 옵션 집합입니다.

입력은 문자열(사용자 메시지로 간주), [입력 항목](/openai-agents-js/openai/agents-core/type-aliases/agentinputitem) 목록, 또는 [휴먼 인 더 루프 (HITL)](/openai-agents-js/ko/guides/human-in-the-loop) 에이전트를 구축하는 경우 [`RunState`](/openai-agents-js/openai/agents-core/classes/runstate) 객체일 수 있습니다.

추가 옵션은 다음과 같습니다:

| Option                  | Default | Description                                                                                                                                                           |
| ----------------------- | ------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `stream`                | `false` | `true` 이면 호출이 `StreamedRunResult` 를 반환하고 모델에서 도착하는 이벤트를 순차적으로 내보냅니다                                                                   |
| `context`               | –       | 모든 도구 / 가드레일 / 핸드오프로 전달되는 컨텍스트 객체입니다. 자세한 내용은 [컨텍스트 관리 가이드](/openai-agents-js/ko/guides/context)를 참고하세요                |
| `maxTurns`              | `10`    | 안전 제한값입니다. 도달 시 [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) 를 발생시킵니다                              |
| `signal`                | –       | 취소를 위한 `AbortSignal` 입니다                                                                                                                                      |
| `session`               | –       | 세션 지속성 구현입니다. [세션 가이드](/openai-agents-js/ko/guides/sessions)를 참고하세요                                                                              |
| `sessionInputCallback`  | –       | 세션 기록과 새 입력을 병합하는 커스텀 로직으로, 모델 호출 전에 실행됩니다. [세션](/openai-agents-js/ko/guides/sessions)을 참고하세요                                  |
| `callModelInputFilter`  | –       | 모델 호출 직전에 모델 입력(항목 + 선택적 instructions)을 수정하는 훅입니다. [Call model input filter](#call-model-input-filter)를 참고하세요                          |
| `toolErrorFormatter`    | –       | 모델로 반환되는 도구 승인 거부 메시지를 커스터마이즈하는 훅입니다. [Tool error formatter](#tool-error-formatter)를 참고하세요                                         |
| `reasoningItemIdPolicy` | –       | 이전 실행 항목을 다시 모델 입력으로 변환할 때 reasoning-item `id` 를 유지할지 생략할지 제어합니다. [Reasoning item ID policy](#reasoning-item-id-policy)를 참고하세요 |
| `tracing`               | –       | 실행 단위 트레이싱 설정 재정의(예: export API key)입니다                                                                                                              |
| `errorHandlers`         | –       | 지원되는 런타임 오류(현재 `maxTurns`)용 핸들러입니다. [Error handlers](#error-handlers)를 참고하세요                                                                  |
| `conversationId`        | –       | 서버 측 대화를 재사용합니다(OpenAI Responses API + Conversations API 전용)                                                                                            |
| `previousResponseId`    | –       | 대화를 생성하지 않고 이전 Responses API 호출에서 이어갑니다(OpenAI Responses API 전용)                                                                                |

### 스트리밍

스트리밍을 사용하면 LLM 실행 중 스트리밍 이벤트를 추가로 받을 수 있습니다. 스트림이 시작되면 `StreamedRunResult` 에는 새로 생성된 모든 출력을 포함해 실행에 관한 전체 정보가 담깁니다. `for await` 루프로 스트리밍 이벤트를 순회할 수 있습니다. 자세한 내용은 [스트리밍 가이드](/openai-agents-js/ko/guides/streaming)를 참고하세요.

### 실행 설정

직접 `Runner` 인스턴스를 만드는 경우 runner 를 설정하기 위해 `RunConfig` 객체를 전달할 수 있습니다.

| Field                       | Type                     | Purpose                                                                                               |
| --------------------------- | ------------------------ | ----------------------------------------------------------------------------------------------------- |
| `model`                     | `string \| Model`        | 실행의 **모든** 에이전트에 특정 모델을 강제 적용합니다                                                |
| `modelProvider`             | `ModelProvider`          | 모델 이름을 해석하며 기본값은 OpenAI provider 입니다                                                  |
| `modelSettings`             | `ModelSettings`          | 에이전트별 설정을 덮어쓰는 전역 튜닝 매개변수입니다                                                   |
| `handoffInputFilter`        | `HandoffInputFilter`     | 핸드오프 수행 시 입력 항목을 변경합니다(핸드오프 자체에 이미 정의되어 있지 않은 경우)                 |
| `inputGuardrails`           | `InputGuardrail[]`       | _초기_ 사용자 입력에 적용되는 가드레일입니다                                                          |
| `outputGuardrails`          | `OutputGuardrail[]`      | _최종_ 출력에 적용되는 가드레일입니다                                                                 |
| `tracingDisabled`           | `boolean`                | OpenAI Tracing 을 완전히 비활성화합니다                                                               |
| `traceIncludeSensitiveData` | `boolean`                | span 은 계속 생성하면서 트레이스에서 LLM/도구 입력 및 출력을 제외합니다                               |
| `workflowName`              | `string`                 | Traces 대시보드에 표시되며 관련 실행을 그룹화하는 데 도움이 됩니다                                    |
| `traceId` / `groupId`       | `string`                 | SDK 가 자동 생성하는 대신 trace 또는 group ID 를 수동 지정합니다                                      |
| `traceMetadata`             | `Record<string, string>` | 모든 span 에 연결할 임의 메타데이터입니다                                                             |
| `tracing`                   | `TracingConfig`          | 실행 단위 트레이싱 재정의(예: export API key)입니다                                                   |
| `sessionInputCallback`      | `SessionInputCallback`   | 이 runner 의 모든 실행에 대한 기본 기록 병합 전략입니다                                               |
| `callModelInputFilter`      | `CallModelInputFilter`   | 각 모델 호출 전에 모델 입력을 수정하는 전역 훅입니다                                                  |
| `toolErrorFormatter`        | `ToolErrorFormatter`     | 모델로 반환되는 도구 승인 거부 메시지를 커스터마이즈하는 전역 훅입니다                                |
| `reasoningItemIdPolicy`     | `ReasoningItemIdPolicy`  | 생성된 항목을 이후 모델 호출에 재사용할 때 reasoning-item `id` 를 유지하거나 생략하는 기본 정책입니다 |

## 상태 및 대화 관리

### 메모리 전략 선택

다음 턴으로 상태를 전달하는 일반적인 방법은 네 가지입니다:

| Strategy             | Where state lives         | Best for                                                    | What you pass on the next turn                       |
| -------------------- | ------------------------- | ----------------------------------------------------------- | ---------------------------------------------------- |
| `result.history`     | 앱 메모리                 | 작은 채팅 루프, 완전한 수동 제어, 모든 provider             | `result.history`                                     |
| `session`            | 저장소 + SDK              | 지속 채팅 상태, 재개 가능한 실행, 커스텀 저장소             | 동일한 `session` 인스턴스(또는 저장소 기반 인스턴스) |
| `conversationId`     | OpenAI Conversations API  | 워커/서비스 전반에서 공유되는 서버 측 상태                  | 동일한 `conversationId` 와 새 사용자 턴만 전달       |
| `previousResponseId` | OpenAI Responses API only | 대화 리소스를 만들지 않는 가장 단순한 서버 관리형 연속 처리 | `result.lastResponseId` 와 새 사용자 턴만 전달       |

`result.history` 와 `session` 은 클라이언트 관리형입니다. `conversationId` 와 `previousResponseId` 는 OpenAI 관리형이며 OpenAI Responses API 를 사용할 때만 적용됩니다. 대부분의 애플리케이션에서는 대화별로 하나의 지속성 전략만 선택하세요. 클라이언트 관리형 기록과 서버 관리형 상태를 섞으면 두 계층을 의도적으로 조정하지 않는 한 컨텍스트가 중복될 수 있습니다.

### 대화 / 채팅 스레드

`runner.run()`(또는 `run()` 유틸리티)의 각 호출은 애플리케이션 수준 대화에서 하나의 **턴** 을 나타냅니다. `RunResult` 중 최종 사용자에게 얼마나 보여줄지는 직접 선택합니다. `finalOutput` 만 보여줄 수도 있고, 생성된 모든 항목을 보여줄 수도 있습니다.

<Code
  lang="typescript"
  code={chatLoopExample}
  title="Example of carrying over the conversation history"
/>

대화형 버전은 [채팅 예제](https://github.com/openai/openai-agents-js/tree/main/examples/basic/chat.ts)를 참고하세요.

#### 서버 관리형 대화

매 턴마다 로컬 대화 기록 전체를 보내는 대신 OpenAI Responses API 가 대화 기록을 지속하도록 할 수 있습니다. 긴 대화나 여러 서비스를 조율할 때 유용합니다. 아래의 서버 관리형 접근 중 어느 쪽이든 매 요청마다 새 턴 입력만 전달하면 됩니다. API 가 이전 상태를 재사용합니다. 자세한 내용은 [Conversation state guide](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses)를 참고하세요.

OpenAI 는 서버 측 상태를 재사용하는 두 가지 방법을 제공합니다:

##### 1. 전체 대화용 `conversationId`

[Conversations API](https://platform.openai.com/docs/api-reference/conversations/create) 로 대화를 한 번 생성한 뒤 모든 턴에서 해당 ID 를 재사용할 수 있습니다. SDK 는 새로 생성된 항목만 자동으로 포함합니다.

<Code
  lang="typescript"
  code={conversationIdExample}
  title="Reusing a server conversation"
/>

##### 2. 마지막 턴에서 이어가기 위한 `previousResponseId`

어차피 Responses API 만으로 시작하려는 경우, 이전 응답에서 반환된 ID 로 각 요청을 체이닝할 수 있습니다. 전체 대화 리소스를 만들지 않고도 턴 간 컨텍스트를 유지할 수 있습니다.

<Code
  lang="typescript"
  code={previousResponseIdExample}
  title="Chaining with previousResponseId"
/>

`conversationId` 와 `previousResponseId` 는 함께 사용할 수 없습니다. 시스템 간 공유 가능한 이름 있는 대화 리소스가 필요하면 `conversationId` 를, 한 응답에서 다음 응답으로 이어지는 가장 저렴한 SDK 수준 연속 처리 기본 구성요소만 원하면 `previousResponseId` 를 사용하세요.

## 훅 및 커스터마이징

### Call model input filter

모델 호출 **직전** 모델 입력을 수정하려면 `callModelInputFilter` 를 사용하세요. 이 훅은 현재 에이전트, 컨텍스트, 결합된 입력 항목(세션 기록이 있으면 포함)을 받습니다. 민감 정보 마스킹, 오래된 메시지 제거, 추가 시스템 가이드 주입 등을 위해 업데이트된 `input` 배열과 선택적 `instructions` 를 반환하세요.

`runner.run(..., { callModelInputFilter })` 로 실행별 설정을 하거나, `Runner` 설정(`RunConfig` 의 `callModelInputFilter`)에서 기본값으로 설정할 수 있습니다.

### Tool error formatter

도구 호출이 거부되었을 때 모델로 되돌려 보내는 승인 거부 메시지를 커스터마이즈하려면 `toolErrorFormatter` 를 사용하세요. 이렇게 하면 SDK 기본 메시지 대신 도메인 특화 문구(예: 컴플라이언스 가이드)를 반환할 수 있습니다.

formatter 는 실행별(`runner.run(..., { toolErrorFormatter })`) 또는 전역(`RunConfig` 의 `toolErrorFormatter`, `new Runner(...)`)으로 설정할 수 있습니다.

현재 formatter 는 `approval_rejected` 이벤트에서 실행되며 다음을 받습니다:

- `kind`(현재 항상 `'approval_rejected'`)
- `toolType`(`'function'`, `'computer'`, `'shell'`, 또는 `'apply_patch'`)
- `toolName`
- `callId`
- `defaultMessage`(SDK 폴백 메시지)
- `runContext`

메시지를 재정의하려면 문자열을 반환하고, SDK 기본값을 유지하려면 `undefined` 를 반환하세요. formatter 가 예외를 던지거나 문자열이 아닌 값을 반환하면 SDK 는 경고를 기록하고 기본 승인 거부 메시지로 폴백합니다.

### Reasoning item ID 정책

SDK 가 이전에 생성된 실행 항목을 이후 모델 입력용 `AgentInputItem[]` 로 다시 변환할 때 reasoning 항목이 `id` 필드를 유지할지 제어하려면 `reasoningItemIdPolicy` 를 사용하세요.

이 설정은 SDK 가 생성된 모델 항목을 입력으로 재생하는 다음 경우에 영향을 줍니다:

- 같은 실행 내 후속 모델 호출(예: 도구 실행 후)
- 생성된 항목을 입력/기록으로 재사용하는 후속 턴
- 저장된 `RunState` 에서 재개된 실행
- `result.history` / `result.output` 같은 파생 결과 뷰(모델 입력 형태의 배열)
- `'preserve'`(기본값)는 reasoning-item ID 를 유지합니다
- `'omit'` 은 입력으로 다시 보내기 전에 reasoning 항목에서 `id` 필드를 제거합니다
- reasoning 이 아닌 항목은 영향받지 않습니다

다음은 **변경되지 않습니다**:

- 원문 모델 응답(`result.rawResponses`)
- 실행 항목(`result.newItems`)
- provider 가 반환한 현재 턴의 모델 출력

즉, 이 정책은 SDK 가 이전 생성 항목으로 **다음 입력** 을 구성할 때 적용됩니다.

정책은 실행별(`runner.run(..., { reasoningItemIdPolicy: 'omit' })`) 또는 runner 기본값(`new Runner({ reasoningItemIdPolicy: 'omit', ... })`)으로 설정할 수 있습니다. 저장된 `RunState` 에서 재개할 때는 재정의하지 않는 한 이전에 결정된 정책이 재사용됩니다.

#### `callModelInputFilter` 와의 상호작용

`reasoningItemIdPolicy` 는 `callModelInputFilter` 전에 적용됩니다. 커스텀 동작이 필요하면 `callModelInputFilter` 에서 준비된 입력을 검사해 모델 호출 전에 reasoning ID 를 수동으로 다시 추가하거나 제거할 수 있습니다.

#### `'omit'` 사용 시점

재생되는 reasoning 항목을 ID 없이 정규화하고 싶다면 `'omit'` 을 사용하세요(예: 전달/재생되는 모델 입력을 단순화하거나 앱 파이프라인의 통합 요구사항에 맞추기 위해).

백엔드/provider 가 재생된 reasoning 항목을 요청 검증 오류로 거부할 때도 유용한 문제 해결 옵션입니다(예: 후속 입력의 reasoning item ID 와 관련된 HTTP `400` 오류). 이런 경우 `'omit'` 으로 재생된 reasoning ID 를 제거하면 백엔드가 새 요청에서 유효하지 않다고 판단하는 ID 전송을 피할 수 있습니다.

재생 입력에서 reasoning-item ID 를 유지하고 통합 환경에서 이를 허용한다면 `'preserve'` 를 유지하세요.

## 오류 및 복구

### 오류 핸들러

예외를 던지는 대신 지원되는 런타임 오류를 최종 출력으로 변환하려면 `errorHandlers` 를 사용하세요. 현재는 `maxTurns` 만 지원됩니다.

- `errorHandlers.maxTurns` 는 최대 턴 오류만 처리합니다
- `errorHandlers.default` 는 지원되는 종류에 대한 폴백으로 사용됩니다
- 핸들러는 `{ error, context, runData }` 를 받고 `{ finalOutput, includeInHistory? }` 를 반환할 수 있습니다

### 예외

SDK 는 catch 가능한 소수의 오류를 발생시킵니다:

- [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) – `maxTurns` 도달
- [`ModelBehaviorError`](/openai-agents-js/openai/agents-core/classes/modelbehaviorerror) – 모델이 잘못된 출력을 생성함(예: 잘못된 JSON, 알 수 없는 도구)
- [`InputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/inputguardrailtripwiretriggered) / [`OutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/outputguardrailtripwiretriggered) – 가드레일 위반
- [`ToolInputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/toolinputguardrailtripwiretriggered) / [`ToolOutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/tooloutputguardrailtripwiretriggered) – 도구 가드레일 위반
- [`GuardrailExecutionError`](/openai-agents-js/openai/agents-core/classes/guardrailexecutionerror) – 가드레일 실행 실패
- [`ToolTimeoutError`](/openai-agents-js/openai/agents-core/classes/tooltimeouterror) – 함수 도구가 `timeoutMs` 를 초과했고 `timeoutBehavior: 'raise_exception'` 을 사용함
- [`ToolCallError`](/openai-agents-js/openai/agents-core/classes/toolcallerror) – 함수 도구 실행이 타임아웃 이외 오류로 실패함
- [`UserError`](/openai-agents-js/openai/agents-core/classes/usererror) – 설정 또는 사용자 입력 기반으로 발생한 오류

모든 오류는 기본 `AgentsError` 클래스를 확장하며, 현재 실행 상태에 접근할 수 있도록 `state` 속성을 제공할 수 있습니다.

아래는 `GuardrailExecutionError` 를 처리하는 코드 예제입니다. 입력 가드레일은 첫 번째 사용자 입력에서만 실행되므로, 이 예제는 원래 입력과 컨텍스트로 실행을 다시 시작합니다. 또한 모델을 다시 호출하지 않고 출력 가드레일을 재시도하기 위해 저장된 상태를 재사용하는 방법도 보여줍니다:

<Code
  lang="typescript"
  code={runningAgentsExceptionExample}
  title="Guardrail execution error"
/>

입력 vs 출력 재시도:

- 입력 가드레일은 실행의 첫 번째 사용자 입력에서만 실행되므로 재시도하려면 같은 입력/컨텍스트로 새 실행을 시작해야 합니다. 저장된 `state` 를 전달해도 입력 가드레일은 다시 트리거되지 않습니다
- 출력 가드레일은 모델 응답 후 실행되므로 `GuardrailExecutionError` 의 저장된 `state` 를 재사용해 추가 모델 호출 없이 출력 가드레일을 다시 실행할 수 있습니다

위 예제를 실행하면 다음 출력이 표시됩니다:

```
Guardrail execution failed (input): Error: Input guardrail failed to complete: Error: Something is wrong!
Math homework input guardrail tripped on retry
Guardrail execution failed (output): Error: Output guardrail failed to complete: Error: Output guardrail crashed.
Output guardrail tripped after retry with saved state
```

---

## 다음 단계

- [모델](/openai-agents-js/ko/guides/models) 설정 방법 알아보기
- 에이전트에 [도구](/openai-agents-js/ko/guides/tools) 제공하기
- 프로덕션 준비를 위해 [가드레일](/openai-agents-js/ko/guides/guardrails) 또는 [트레이싱](/openai-agents-js/ko/guides/tracing) 추가하기
