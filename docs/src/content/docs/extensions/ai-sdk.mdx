---
title: Using any model with the Vercel's AI SDK
description: Connect your Agents SDK agents to any model through the Vercel's AI SDK
---

import { Aside, Steps, Code } from '@astrojs/starlight/components';
import aiSdkImportsExample from '../../../../../examples/docs/extensions/ai-sdk-imports.ts?raw';
import aiSdkModelExample from '../../../../../examples/docs/extensions/ai-sdk-model.ts?raw';
import aiSdkProviderDataExample from '../../../../../examples/docs/extensions/ai-sdk-providerData.ts?raw';
import aiSdkProviderMetadataExample from '../../../../../examples/docs/extensions/ai-sdk-providerMetadata.ts?raw';
import aiSdkSetupExample from '../../../../../examples/docs/extensions/ai-sdk-setup.ts?raw';
import aiSdkUiMessageStreamResponseExample from '../../../../../examples/docs/extensions/ai-sdk-ui-message-stream-response.ts?raw';
import aiSdkTextStreamResponseExample from '../../../../../examples/docs/extensions/ai-sdk-text-stream-response.ts?raw';

<Aside type="caution">
  This adapter is still in beta. You may run into issues with some model
  providers, especially smaller ones. Please report any issues via [GitHub
  issues](https://github.com/openai/openai-agents-js/issues) and we'll fix
  quickly.
</Aside>

Out of the box the Agents SDK works with OpenAI models through the Responses API or Chat Completions API. However, if you would like to use another model, the [Vercel AI SDK](https://sdk.vercel.ai/) offers a range of supported models that can be brought into the Agents SDK through this adapter.

## Setup

<Steps>

1. Install the AI SDK adapter by installing the extensions package:

   ```bash
   npm install @openai/agents-extensions
   ```

2. Choose your desired model package from the [Vercel's AI SDK](https://ai-sdk.dev/docs/foundations/providers-and-models) and install it:

   ```bash
   npm install @ai-sdk/openai
   ```

3. Import the adapter and model to connect to your agent:

   <Code
     lang="typescript"
     code={aiSdkImportsExample}
     title="Import the adapter"
   />

4. Initialize an instance of the model to be used by the agent:

   <Code lang="typescript" code={aiSdkModelExample} title="Create the model" />

</Steps>

<Aside type="caution">
  We support AI SDK providers that expose `specificationVersion` `v2` or `v3`.
  If you have a specific reason to continue using the older v1 provider style,
  you can copy the module from
  [examples/ai-sdk-v1](https://github.com/openai/openai-agents-js/tree/main/examples/ai-sdk-v1)
  and include it in your project.
</Aside>

## Example

<Code lang="typescript" code={aiSdkSetupExample} title="AI SDK Setup" />

## Passing provider metadata

If you need to send provider-specific options with a message, pass them through `providerMetadata`. The values are forwarded directly to the underlying AI SDK model. For example, the following `providerData` in the Agents SDK

<Code
  lang="typescript"
  code={aiSdkProviderDataExample}
  title="Agents SDK providerData"
/>

would become

<Code
  lang="typescript"
  code={aiSdkProviderMetadataExample}
  title="AI SDK providerMetadata"
/>

when using the AI SDK integration.

## Picking the right integration

There are two related integrations in `@openai/agents-extensions`:

- `@openai/agents-extensions/ai-sdk` adapts an AI SDK model so an `Agent` can run on it.
- `@openai/agents-extensions/ai-sdk-ui` adapts a streamed Agents SDK run so AI SDK UI routes can return a standard streaming `Response`.

## AI SDK UI stream helpers

`@openai/agents-extensions/ai-sdk-ui` provides response helpers for wiring Agents SDK streams into AI SDK UI routes:

- `createAiSdkTextStreamResponse(source, options?)` for plain text streaming responses.
- `createAiSdkUiMessageStreamResponse(source, options?)` for `UIMessageChunk` streaming responses.

Both helpers accept a `StreamedRunResult`, stream-like source, or compatible wrapper object and return a `Response` with streaming-friendly headers.

Use `createAiSdkUiMessageStreamResponse(...)` when your UI needs structured chunks such as tool calls or reasoning parts. Use `createAiSdkTextStreamResponse(...)` when you only want plain text.

Example Next.js route for UI message streaming:

<Code
  lang="typescript"
  code={aiSdkUiMessageStreamResponseExample}
  title="UI message stream response"
/>

Example Next.js route for text-only streaming:

<Code
  lang="typescript"
  code={aiSdkTextStreamResponseExample}
  title="Text stream response"
/>

For end-to-end usage, see the `examples/ai-sdk-ui` app in this repository.
