---
title: 工具
description: Provide your agents with capabilities via hosted tools or custom function tools
---

import { Code } from '@astrojs/starlight/components';
import toolsFunctionExample from '../../../../../../examples/docs/tools/functionTools.ts?raw';
import toolsHostedToolsExample from '../../../../../../examples/docs/tools/hostedTools.ts?raw';
import localBuiltInToolsExample from '../../../../../../examples/docs/tools/localBuiltInTools.ts?raw';
import nonStrictSchemaTools from '../../../../../../examples/docs/tools/nonStrictSchemaTools.ts?raw';
import agentsAsToolsExample from '../../../../../../examples/docs/tools/agentsAsTools.ts?raw';
import agentsAsToolsStreamingExample from '../../../../../../examples/docs/tools/agentsAsToolsStreaming.ts?raw';
import mcpLocalServer from '../../../../../../examples/docs/tools/mcpLocalServer.ts?raw';
import codexToolExample from '../../../../../../examples/docs/tools/codexTool.ts?raw';
import codexRunContextThreadExample from '../../../../../../examples/docs/tools/codexRunContextThread.ts?raw';

工具让一个智能体能够**执行操作**——获取数据、调用外部 API、执行代码，甚至进行计算机操作。JavaScript/TypeScript SDK 支持六大类别：

1. **托管的 OpenAI 工具** —— 在 OpenAI 服务器上与模型并行运行。（Web 搜索、文件搜索、Code Interpreter、图像生成）
2. **本地内置工具** —— 在你的环境中运行。（计算机操作、shell、apply_patch）
3. **函数工具** —— 使用 JSON Schema 包装任意本地函数，让 LLM 可以调用。
4. **Agents as tools** —— 将整个智能体暴露为可调用的工具。
5. **MCP 服务器** —— 挂载一个 Model Context Protocol 服务器（本地或远程）。
6. **实验性：Codex 工具** —— 将 Codex SDK 包装为函数工具，以运行具备工作区上下文的任务。

---

## 工具类别

本指南的其余部分将先介绍每个工具类别，然后总结跨工具的选择与提示词编写指南。

### 1. 托管工具（OpenAI Responses API）

当你使用 `OpenAIResponsesModel` 时，可以添加以下内置工具：

| 工具             | 类型字符串           | 目的                             |
| ---------------- | -------------------- | -------------------------------- |
| Web 搜索         | `'web_search'`       | 互联网搜索。                     |
| 文件/检索搜索    | `'file_search'`      | 查询托管在 OpenAI 上的向量存储。 |
| Code Interpreter | `'code_interpreter'` | 在沙箱环境中运行代码。           |
| 图像生成         | `'image_generation'` | 基于文本生成图像。               |

<Code lang="typescript" code={toolsHostedToolsExample} title="托管工具" />

SDK 提供了返回托管工具定义的辅助函数：

| 辅助函数                        | 说明                                                                                        |
| ------------------------------- | ------------------------------------------------------------------------------------------- |
| `webSearchTool(options?)`       | 便于 JS 使用的选项，如 `searchContextSize`、`userLocation`、以及 `filters.allowedDomains`。 |
| `fileSearchTool(ids, options?)` | 第一个参数接受一个或多个向量存储 ID，另有 `maxNumResults` 和过滤器等选项。                  |
| `codeInterpreterTool(options?)` | 当未提供 `container` 时，默认使用自动托管容器。                                             |
| `imageGenerationTool(options?)` | 支持图像生成配置，如 `size`、`quality`、`background` 和输出格式。                           |

这些辅助函数会将更贴合 JavaScript/TypeScript 的选项名映射到底层的 OpenAI Responses API 工具负载。完整的工具 schema 以及排序选项、语义过滤等高级选项请参考 OpenAI 官方文档。

---

### 2. 本地内置工具

本地内置工具在你自己的环境中运行，需要你提供实现：

- **计算机操作** —— 实现 `Computer` 接口并传给 `computerTool()`。
- **Shell** —— 提供本地的 `Shell` 实现，或配置托管容器环境。
- **Apply patch** —— 实现 `Editor` 接口并传给 `applyPatchTool()`。

计算机操作和 apply‑patch 工具在本地执行，**不**由 OpenAI 托管。Shell 工具可根据 `shellTool()` 的配置选择在本地或托管容器环境运行。
工具调用仍由模型的响应来请求，但你的应用控制这些调用的执行方式。

<Code lang="typescript" code={localBuiltInToolsExample} title="本地内置工具" />

对于托管的 shell 环境，通过如下方式配置 `shellTool({ environment })`：

- `type: 'container_auto'` 为本次运行创建一个托管容器（支持网络策略、内存限制和技能）。
- `type: 'container_reference'` 通过 `containerId` 复用现有容器。

端到端用法请参见 `examples/tools/container-shell-skill-ref.ts` 和 `examples/tools/container-shell-inline-skill.ts`。

---

### 3. 函数工具

你可以使用 `tool()` 辅助函数将**任意**函数变成工具。

<Code
  lang="typescript"
  code={toolsFunctionExample}
  title="使用 Zod 参数的函数工具"
/>

#### 选项参考

| 字段                   | 必需 | 描述                                                                                                                                                                                                        |
| ---------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`                 | 否   | 默认为函数名（例如 `get_weather`）。                                                                                                                                                                        |
| `description`          | 是   | 展示给 LLM 的清晰、可读的人类描述。                                                                                                                                                                         |
| `parameters`           | 是   | Zod schema 或原始 JSON Schema 对象。使用 Zod 参数会自动启用 **strict** 模式。                                                                                                                               |
| `strict`               | 否   | 当为 `true`（默认）且参数校验失败时，SDK 会返回模型错误。设为 `false` 允许模糊匹配。                                                                                                                        |
| `execute`              | 是   | `(args, context, details) => string \| unknown \| Promise<...>` —— 你的业务逻辑。非字符串输出会序列化给模型。`context` 是可选的 `RunContext`；`details` 包含 `toolCall`、`resumeState`、`signal` 等元数据。 |
| `errorFunction`        | 否   | 自定义处理器 `(context, error) => string`，将内部错误转化为对用户可见的字符串。                                                                                                                             |
| `timeoutMs`            | 否   | 每次调用的超时时间（毫秒）。必须大于 0 且小于等于 `2147483647`。                                                                                                                                            |
| `timeoutBehavior`      | 否   | 超时模式：`error_as_result`（默认）向模型返回超时信息；`raise_exception` 抛出 `ToolTimeoutError`。                                                                                                          |
| `timeoutErrorFunction` | 否   | 当 `timeoutBehavior` 为 `error_as_result` 时，自定义 `(context, timeoutError) => string` 的超时输出。                                                                                                       |
| `needsApproval`        | 否   | 在执行前需要人工批准。参见[人机协作](/openai-agents-js/zh/guides/human-in-the-loop)。                                                                                                                       |
| `isEnabled`            | 否   | 按运行条件性地暴露该工具；接受布尔值或谓词。                                                                                                                                                                |
| `inputGuardrails`      | 否   | 工具执行前运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                                                                                                    |
| `outputGuardrails`     | 否   | 工具执行后运行的护栏；可拒绝或抛出。参见[护栏](/openai-agents-js/zh/guides/guardrails#tool-guardrails)。                                                                                                    |

#### 函数工具超时

使用 `timeoutMs` 为每次函数工具调用设置上限。

- `timeoutBehavior: 'error_as_result'`（默认）会向模型返回 `Tool '<name>' timed out after <timeoutMs>ms.`。
- `timeoutBehavior: 'raise_exception'` 会抛出 [`ToolTimeoutError`](/openai-agents-js/openai/agents-core/classes/tooltimeouterror)，你可以作为[运行异常](/openai-agents-js/zh/guides/running-agents#exceptions)的一部分进行捕获。
- `timeoutErrorFunction` 允许你在 `error_as_result` 模式下自定义超时文本。
- 超时会中止 `details.signal`，因此长时间运行的工具在监听到取消时可以及时停止。

如果你直接调用函数工具，请使用 [`invokeFunctionTool`](/openai-agents-js/openai/agents/functions/invokefunctiontool) 以强制执行与常规智能体运行相同的超时行为。

#### 非严格 JSON Schema 工具

如果你需要模型去“猜测”无效或不完整的输入，可以在使用原始 JSON Schema 时禁用严格模式：

<Code
  lang="typescript"
  code={nonStrictSchemaTools}
  title="非严格模式的 JSON Schema 工具"
/>

---

### 4. Agents as tools

有时你希望一个智能体在不完全接管对话的情况下去“协助”另一个智能体。使用 `agent.asTool()`：

<Code lang="typescript" code={agentsAsToolsExample} title="Agents as tools" />

在底层，SDK 会：

- 创建一个仅包含 `input` 参数的函数工具。
- 当工具被调用时，使用该输入运行子智能体。
- 返回最后一条消息，或由 `customOutputExtractor` 提取的输出。

当你以工具形式运行一个智能体时，Agents SDK 会使用默认设置创建一个 runner，并在函数执行中用它来运行该智能体。如果你想提供 `runConfig` 或 `runOptions` 的任意属性，可以将它们传给 `asTool()` 方法以自定义 runner 的行为。

你也可以通过 `asTool()` 选项在智能体工具上设置 `needsApproval` 和 `isEnabled`，以集成人工干预流程和条件性工具可用性。

`agent.asTool()` 的高级结构化输入选项：

- `inputBuilder`：将结构化的工具参数映射到嵌套智能体的输入负载。
- `includeInputSchema`：在嵌套运行中包含输入 JSON Schema，以获得更强的 schema 感知行为。
- `resumeState`：在恢复嵌套的已序列化 `RunState` 时，控制上下文对齐策略。

#### 来自智能体工具的流式事件

智能体工具可以将所有嵌套运行事件流式回传到你的应用。根据你构建工具的方式选择合适的钩子风格：

<Code
  lang="typescript"
  code={agentsAsToolsStreamingExample}
  title="智能体工具的流式传输"
/>

- 事件类型与 `RunStreamEvent['type']` 一致：`raw_model_stream_event`、`run_item_stream_event`、`agent_updated_stream_event`。
- `onStream` 是最简单的“总线式”方案，适合内联声明工具时使用（`tools: [agent.asTool({ onStream })]`）。如果你不需要按事件路由，请使用它。
- `on(eventName, handler)` 允许你选择性订阅（或使用 `'*'`），最适合需要更细粒度处理或在创建后附加监听器的情况。
- 只要提供了 `onStream` 或任意 `on(...)` 处理器，agent‑as‑tool 将自动以流式模式运行；否则保持非流式路径。
- 处理器并行调用，因此较慢的 `onStream` 回调不会阻塞 `on(...)` 处理器（反之亦然）。
- 当工具是通过模型的工具调用触发时会提供 `toolCallId`；直接 `invoke()` 调用或某些提供方的特性可能会省略它。

---

### 5. MCP 服务器

你可以通过 [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) 服务器暴露工具，并将其挂载到智能体。
例如，你可以使用 `MCPServerStdio` 来启动并连接到 stdio MCP 服务器：

<Code lang="typescript" code={mcpLocalServer} title="本地 MCP 服务器" />

完整示例参见 [`filesystem-example.ts`](https://github.com/openai/openai-agents-js/tree/main/examples/mcp/filesystem-example.ts)。此外，如果你在寻找关于 MCP 服务器工具集成的综合指南，请参考[MCP 集成](/openai-agents-js/zh/guides/mcp)。在管理多个服务器（或部分失败）时，请使用 `connectMcpServers`，并遵循 [MCP 集成](/openai-agents-js/zh/guides/mcp#managing-mcp-server-lifecycle) 中的生命周期建议。

---

### 6. 实验性：Codex 工具

`@openai/agents-extensions/experimental/codex` 提供 `codexTool()`，它是一个函数工具，可将模型的工具调用路由到 Codex SDK，从而让智能体可以自主运行基于工作区范围的任务（shell、文件编辑、MCP 工具）。该接口为实验性，可能发生变化。

首先安装依赖：

```bash
npm install @openai/agents-extensions @openai/codex-sdk
```

快速上手：

<Code lang="typescript" code={codexToolExample} title="实验性 Codex 工具" />

须知：

- 认证：提供 `CODEX_API_KEY`（首选）或 `OPENAI_API_KEY`，也可传入 `codexOptions.apiKey`。
- 输入：严格的 schema——`inputs` 至少包含一个 `{ type: 'text', text }` 或 `{ type: 'local_image', path }`。
- 安全：将 `sandboxMode` 与 `workingDirectory` 搭配使用；如果目录不是 Git 仓库，请设置 `skipGitRepoCheck`。
- 线程：`useRunContextThreadId: true` 会在 `runContext.context` 中读取/存储最新的线程 ID，便于在你的应用状态中跨轮次复用。
- 线程 ID 优先级：工具调用的 `threadId`（若你的 schema 包含它）优先，其次是运行上下文中的线程 ID，然后是 `codexTool({ threadId })`。
- 运行上下文键：`name: 'codex'` 时默认为 `codexThreadId`；名称如 `name: 'engineer'` 时为 `codexThreadId_<suffix>`（规范化后为 `codex_engineer`）。
- 可变上下文要求：启用 `useRunContextThreadId` 时，在 `run(..., { context })` 传入可变对象或 `Map`。
- 命名：工具名称会规范化到 `codex` 命名空间（`engineer` 变为 `codex_engineer`），同一智能体内重复的 Codex 工具名会被拒绝。
- 流式传输：`onStream` 会镜像 Codex 事件（推理、命令执行、MCP 工具调用、文件变更、Web 搜索），便于记录或追踪进度。
- 输出：工具结果包含 `response`、`usage` 和 `threadId`，且 Codex 的 token 使用会记录在 `RunContext` 中。
- 结构：`outputSchema` 可为描述符、JSON Schema 对象或 Zod 对象。对 JSON 对象类型的 schema，`additionalProperties` 必须为 `false`。

运行上下文线程复用示例：

<Code
  lang="typescript"
  code={codexRunContextThreadExample}
  title="Codex 运行上下文线程复用"
/>

---

## 工具策略与最佳实践

### 工具使用行为

关于控制模型何时以及如何必须使用工具（`modelSettings.toolChoice`、`toolUseBehavior` 等），请参考[智能体](/openai-agents-js/zh/guides/agents#forcing-tool-use)。

---

### 最佳实践

- **简短、明确的描述** —— 说明工具做了什么、以及何时使用它。
- **校验输入** —— 尽可能使用 Zod schema 进行严格的 JSON 校验。
- **避免在错误处理器中产生副作用** —— `errorFunction` 应返回有用的字符串，而不是抛出异常。
- **单一职责的工具** —— 小而可组合的工具有助于提升模型推理质量。

---

## 下一步

- 了解[强制使用工具](/openai-agents-js/zh/guides/agents#forcing-tool-use)。
- 添加[护栏](/openai-agents-js/zh/guides/guardrails)以校验工具的输入或输出。
- 查阅 TypeDoc 参考文档以了解 [`tool()`](/openai-agents-js/openai/agents/functions/tool) 和各类托管工具类型。
