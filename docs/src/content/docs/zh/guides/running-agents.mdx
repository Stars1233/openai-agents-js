---
title: 运行智能体
description: Configure and execute agent workflows with the Runner class
---

import { Aside, Code } from '@astrojs/starlight/components';
import helloWorldWithRunnerExample from '../../../../../../examples/docs/hello-world-with-runner.ts?raw';
import helloWorldExample from '../../../../../../examples/docs/hello-world.ts?raw';
import runningAgentsExceptionExample from '../../../../../../examples/docs/running-agents/exceptions1.ts?raw';
import chatLoopExample from '../../../../../../examples/docs/running-agents/chatLoop.ts?raw';
import conversationIdExample from '../../../../../../examples/docs/running-agents/conversationId.ts?raw';
import previousResponseIdExample from '../../../../../../examples/docs/running-agents/previousResponseId.ts?raw';

智能体本身不会执行任何操作——你需要使用 `Runner` 类或 `run()` 工具来**运行**它们。

<Code lang="typescript" code={helloWorldExample} title="Simple run" />

当你不需要自定义 runner 时，也可以使用 `run()` 工具，它会运行一个默认的单例 `Runner` 实例。

或者，你也可以创建自己的 runner 实例：

<Code lang="typescript" code={helloWorldWithRunnerExample} title="Simple run" />

运行智能体后，你会收到一个[执行结果](/openai-agents-js/zh/guides/results)对象，其中包含最终输出和本次运行的完整历史记录。

## Runner 生命周期与配置

### 智能体循环

当你在 Runner 中使用 run 方法时，需要传入一个起始智能体和输入。输入可以是字符串（会被视为用户消息），也可以是输入项列表（即 OpenAI Responses API 中的 items）。

随后 runner 会执行一个循环：

1. 使用当前输入调用当前智能体的模型。
2. 检查 LLM 响应。
   - **最终输出** → 返回。
   - **交接** → 切换到新智能体，保留已累计的对话历史，回到 1。
   - **工具调用** → 执行工具，将结果追加到对话中，回到 1。
3. 达到 `maxTurns` 后抛出 [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror)。

<Aside type="note">
  判断 LLM 输出是否为“最终输出”的规则是：
  其产出了目标类型的文本输出，且没有工具调用。
</Aside>

#### Runner 生命周期

在应用启动时创建一个 `Runner`，并在各请求间复用它。该实例会
保存全局配置，例如模型提供方和追踪选项。只有在你需要完全不同的配置时，
才创建另一个 `Runner`。对于简单脚本，也可以直接调用 `run()`，
它会在内部使用默认 runner。

### 运行参数

`run()` 方法的输入包括：用于启动运行的初始智能体、运行输入，以及一组选项。

输入可以是字符串（会被视为用户消息）、[input items](/openai-agents-js/openai/agents-core/type-aliases/agentinputitem) 列表，或者在构建[人机协作](/openai-agents-js/zh/guides/human-in-the-loop)智能体时传入 [`RunState`](/openai-agents-js/openai/agents-core/classes/runstate) 对象。

附加选项如下：

| 选项                    | 默认值  | 说明                                                                                                                           |
| ----------------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------ |
| `stream`                | `false` | 若为 `true`，调用会返回 `StreamedRunResult`，并在模型返回事件时持续发出事件。                                                  |
| `context`               | –       | 传递给每个工具 / 护栏 / 交接的上下文对象。详见[上下文管理指南](/openai-agents-js/zh/guides/context)。                          |
| `maxTurns`              | `10`    | 安全限制——达到后抛出 [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror)。           |
| `signal`                | –       | 用于取消的 `AbortSignal`。                                                                                                     |
| `session`               | –       | 会话持久化实现。参见[会话指南](/openai-agents-js/zh/guides/sessions)。                                                         |
| `sessionInputCallback`  | –       | 用于合并会话历史与新输入的自定义逻辑；在模型调用前运行。参见[会话](/openai-agents-js/zh/guides/sessions)。                     |
| `callModelInputFilter`  | –       | 在调用模型前编辑模型输入（items + 可选 instructions）的钩子。参见[模型输入过滤](#call-model-input-filter)。                    |
| `toolErrorFormatter`    | –       | 自定义返回给模型的工具审批拒绝消息的钩子。参见[工具错误格式化器](#tool-error-formatter)。                                      |
| `reasoningItemIdPolicy` | –       | 控制在将先前运行项回转为模型输入时，是否保留 reasoning-item 的 `id`。参见[Reasoning item ID 策略](#reasoning-item-id-policy)。 |
| `tracing`               | –       | 每次运行的追踪配置覆盖（例如导出 API key）。                                                                                   |
| `errorHandlers`         | –       | 对受支持运行时错误的处理器（当前为 `maxTurns`）。参见[错误处理器](#error-handlers)。                                           |
| `conversationId`        | –       | 复用服务端会话（仅 OpenAI Responses API + Conversations API）。                                                                |
| `previousResponseId`    | –       | 从上一次 Responses API 调用继续而不创建会话（仅 OpenAI Responses API）。                                                       |

### 流式传输

流式传输允许你在 LLM 运行时额外接收流式事件。流启动后，`StreamedRunResult` 将包含本次运行的完整信息，包括所有新产生的输出。你可以使用 `for await` 循环遍历流式事件。更多内容见[流式传输指南](/openai-agents-js/zh/guides/streaming)。

### RunConfig 配置

如果你要创建自己的 `Runner` 实例，可以传入 `RunConfig` 对象来配置 runner。

| 字段                        | 类型                     | 用途                                                                          |
| --------------------------- | ------------------------ | ----------------------------------------------------------------------------- |
| `model`                     | `string \| Model`        | 为本次运行中的**所有**智能体强制指定模型。                                    |
| `modelProvider`             | `ModelProvider`          | 解析模型名称——默认使用 OpenAI provider。                                      |
| `modelSettings`             | `ModelSettings`          | 全局调优参数，会覆盖每个智能体的设置。                                        |
| `handoffInputFilter`        | `HandoffInputFilter`     | 执行交接时变更输入项（前提是交接本身未定义）。                                |
| `inputGuardrails`           | `InputGuardrail[]`       | 应用于*初始*用户输入的护栏。                                                  |
| `outputGuardrails`          | `OutputGuardrail[]`      | 应用于*最终*输出的护栏。                                                      |
| `tracingDisabled`           | `boolean`                | 完全禁用 OpenAI 追踪。                                                        |
| `traceIncludeSensitiveData` | `boolean`                | 从追踪中排除 LLM/工具输入与输出，但仍会发出 span。                            |
| `workflowName`              | `string`                 | 显示在 Traces 控制台中——有助于归类相关运行。                                  |
| `traceId` / `groupId`       | `string`                 | 手动指定 trace 或 group ID，而不是由 SDK 自动生成。                           |
| `traceMetadata`             | `Record<string, string>` | 附加到每个 span 的任意元数据。                                                |
| `tracing`                   | `TracingConfig`          | 每次运行的追踪覆盖配置（例如导出 API key）。                                  |
| `sessionInputCallback`      | `SessionInputCallback`   | 此 runner 上所有运行的默认历史合并策略。                                      |
| `callModelInputFilter`      | `CallModelInputFilter`   | 每次模型调用前编辑模型输入的全局钩子。                                        |
| `toolErrorFormatter`        | `ToolErrorFormatter`     | 自定义返回给模型的工具审批拒绝消息的全局钩子。                                |
| `reasoningItemIdPolicy`     | `ReasoningItemIdPolicy`  | 在将已生成项重放到后续模型调用时，保留或省略 reasoning-item `id` 的默认策略。 |

## 状态与对话管理

### 内存策略选择

将状态带入下一轮的常见方式有四种：

| 策略                 | 状态存储位置             | 最适用场景                                | 下一轮传入内容                                    |
| -------------------- | ------------------------ | ----------------------------------------- | ------------------------------------------------- |
| `result.history`     | 应用内存                 | 小型聊天循环、完全手动控制、任意 provider | `result.history`                                  |
| `session`            | 你的存储 + SDK           | 持久聊天状态、可恢复运行、自定义存储      | 同一个 `session` 实例（或基于存储的实例）         |
| `conversationId`     | OpenAI Conversations API | 在 worker/服务间共享服务端状态            | 相同的 `conversationId`，外加仅新增的用户轮次输入 |
| `previousResponseId` | 仅 OpenAI Responses API  | 不创建会话时最简单的服务端续接方式        | `result.lastResponseId`，外加仅新增的用户轮次输入 |

`result.history` 和 `session` 是客户端管理。`conversationId` 与 `previousResponseId`
由 OpenAI 管理，仅适用于使用 OpenAI Responses API 的场景。在大多数应用中，
每段对话只选择一种持久化策略。除非你有意协调两层状态，否则混用客户端历史与服务端状态
可能导致上下文重复。

### 会话 / 聊天线程

在你的应用层对话中，每次调用 `runner.run()`（或 `run()` 工具）都表示一个**轮次**。你可以自行决定向终端用户展示多少 `RunResult` 内容——有时只展示 `finalOutput`，有时展示所有生成项。

<Code
  lang="typescript"
  code={chatLoopExample}
  title="Example of carrying over the conversation history"
/>

交互式版本见[聊天示例](https://github.com/openai/openai-agents-js/tree/main/examples/basic/chat.ts)。

#### 服务端管理会话

你可以让 OpenAI Responses API 为你持久化会话历史，而不必在每一轮都发送
完整本地历史。这在你协调长对话或多个服务时很有用。使用以下任一服务端方式时，
每次请求只需传入当前轮次的新输入。API 会自动复用先前状态。详情见
[会话状态指南](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses)。

OpenAI 提供了两种复用服务端状态的方法：

##### 1. 使用 `conversationId` 表示整段会话

你可以先通过 [Conversations API](https://platform.openai.com/docs/api-reference/conversations/create) 创建一次会话，然后在每一轮复用其 ID。SDK 会自动仅包含新生成的项。

<Code
  lang="typescript"
  code={conversationIdExample}
  title="Reusing a server conversation"
/>

##### 2. 使用 `previousResponseId` 从上一轮继续

如果你只想从 Responses API 开始，也可以使用上一条响应返回的 ID 链式发起下一次请求。这样无需创建完整会话资源，也能在轮次间保留上下文。

<Code
  lang="typescript"
  code={previousResponseIdExample}
  title="Chaining with previousResponseId"
/>

`conversationId` 和 `previousResponseId` 互斥。若你
希望拥有可在多系统共享的命名会话资源，请用 `conversationId`；若你
只需要从一个响应到下一个响应的低成本 SDK 续接原语，请用 `previousResponseId`。

## 钩子与自定义能力

### 模型输入过滤

使用 `callModelInputFilter` 在模型调用**前一刻**编辑模型输入。该钩子会接收当前智能体、context 和合并后的输入项（包含存在时的会话历史）。你可以返回更新后的 `input` 数组和可选 `instructions`，用于脱敏、丢弃旧消息或注入额外系统指导。

你可以在单次运行中设置（`runner.run(..., { callModelInputFilter })`），也可以在 `Runner` 配置中设置默认值（`RunConfig` 中的 `callModelInputFilter`）。

### 工具错误格式化器

使用 `toolErrorFormatter` 自定义当工具调用被拒绝时，回传给模型的审批拒绝消息。这样你可以返回领域特定措辞（例如合规指引），而不是 SDK 默认消息。

该格式化器可按次运行设置（`runner.run(..., { toolErrorFormatter })`），也可在 `RunConfig` 中全局设置（`new Runner(...)` 中的 `toolErrorFormatter`）。

该格式化器目前在 `approval_rejected` 事件上运行，接收：

- `kind`（当前恒为 `'approval_rejected'`）
- `toolType`（`'function'`、`'computer'`、`'shell'` 或 `'apply_patch'`）
- `toolName`
- `callId`
- `defaultMessage`（SDK 回退消息）
- `runContext`

返回字符串可覆盖消息；返回 `undefined` 则保留 SDK 默认值。若格式化器抛错（或返回非字符串值），SDK 会记录警告并回退到默认审批拒绝消息。

### Reasoning item ID 策略

使用 `reasoningItemIdPolicy` 控制：当 SDK 将先前生成的运行项转换回 `AgentInputItem[]` 供后续模型输入时，reasoning items 是否保留其 `id` 字段。

这会影响 SDK 将模型生成项重放为输入的场景，例如：

- 同一次运行中的后续模型调用（例如工具执行后）；
- 在后续轮次中复用生成项作为输入/历史；
- 从保存的 `RunState` 恢复运行；
- 派生结果视图，如 `result.history` / `result.output`（其数组形状与模型输入一致）。
- `'preserve'`（默认）保留 reasoning-item ID。
- `'omit'` 会在将 reasoning items 回传为输入前移除 `id` 字段。
- 非 reasoning items 不受影响。

该策略**不会**改变：

- 原始模型响应（`result.rawResponses`）；
- 运行项（`result.newItems`）；
- provider 返回的本轮模型输出。

也就是说，该策略作用于 SDK 基于先前生成项构建**下一次输入**时。

你可以按次运行设置（`runner.run(..., { reasoningItemIdPolicy: 'omit' })`），也可设置为 runner 默认值（`new Runner({ reasoningItemIdPolicy: 'omit', ... })`）。从保存的 `RunState` 恢复时，会复用先前已解析的策略，除非你显式覆盖。

#### 与 `callModelInputFilter` 的交互

`reasoningItemIdPolicy` 会先于 `callModelInputFilter` 应用。若你需要自定义行为，`callModelInputFilter` 仍可检查已准备好的输入，并在模型调用前手动重新添加或移除 reasoning ID。

#### 何时使用 `'omit'`

当你希望重放的 reasoning items 以不带 ID 的形式归一化时，可使用 `'omit'`（例如让转发/重放的模型输入更简洁，或满足应用流水线集成要求）。

如果后端/provider 因请求校验错误而拒绝带重放 reasoning items 的请求（例如后续输入中 reasoning item ID 相关的 HTTP `400` 错误），这也是一个有用的排障选项。此时使用 `'omit'` 移除重放 reasoning ID，可避免发送被后端视为无效的新请求 ID。

如果你希望 SDK 在重放输入中保留 reasoning-item ID，且你的集成可接受这些 ID，请保持 `'preserve'`。

## 错误与恢复

### 错误处理器

使用 `errorHandlers` 可将受支持的运行时错误转换为最终输出，而不是抛出异常。目前仅支持 `maxTurns`。

- `errorHandlers.maxTurns` 仅处理最大轮次错误。
- `errorHandlers.default` 作为受支持类型的回退处理器。
- 处理器接收 `{ error, context, runData }`，可返回 `{ finalOutput, includeInHistory? }`。

### 异常

SDK 会抛出少量可捕获错误：

- [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror)——达到 `maxTurns`。
- [`ModelBehaviorError`](/openai-agents-js/openai/agents-core/classes/modelbehaviorerror)——模型产生无效输出（如格式错误 JSON、未知工具）。
- [`InputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/inputguardrailtripwiretriggered) / [`OutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/outputguardrailtripwiretriggered)——护栏违规。
- [`ToolInputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/toolinputguardrailtripwiretriggered) / [`ToolOutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/tooloutputguardrailtripwiretriggered)——工具护栏违规。
- [`GuardrailExecutionError`](/openai-agents-js/openai/agents-core/classes/guardrailexecutionerror)——护栏执行未完成。
- [`ToolTimeoutError`](/openai-agents-js/openai/agents-core/classes/tooltimeouterror)——函数工具超过 `timeoutMs` 且使用 `timeoutBehavior: 'raise_exception'`。
- [`ToolCallError`](/openai-agents-js/openai/agents-core/classes/toolcallerror)——函数工具执行失败（非超时错误）。
- [`UserError`](/openai-agents-js/openai/agents-core/classes/usererror)——基于配置或用户输入抛出的任意错误。

上述错误都继承自 `AgentsError` 基类，该类可通过 `state` 属性访问当前运行状态。

下面是一个处理 `GuardrailExecutionError` 的代码示例。由于输入护栏只在首次用户输入时运行，示例会使用原始输入和 context 重新启动运行。它还展示了如何复用保存的 state，在不再次调用模型的情况下重试输出护栏：

<Code
  lang="typescript"
  code={runningAgentsExceptionExample}
  title="Guardrail execution error"
/>

输入重试与输出重试：

- 输入护栏仅在一次运行的第一条用户输入上执行，因此要重试它们，必须用相同输入/context 启动全新运行——传入保存的 `state` 不会再次触发输入护栏。
- 输出护栏在模型响应后执行，因此你可以复用 `GuardrailExecutionError` 中保存的 `state` 重新运行输出护栏，而无需再次调用模型。

运行上述示例时，你将看到以下输出：

```
Guardrail execution failed (input): Error: Input guardrail failed to complete: Error: Something is wrong!
Math homework input guardrail tripped on retry
Guardrail execution failed (output): Error: Output guardrail failed to complete: Error: Output guardrail crashed.
Output guardrail tripped after retry with saved state
```

---

## 后续步骤

- 了解如何[配置模型](/openai-agents-js/zh/guides/models)。
- 为你的智能体提供[工具](/openai-agents-js/zh/guides/tools)。
- 添加[护栏](/openai-agents-js/zh/guides/guardrails)或[追踪](/openai-agents-js/zh/guides/tracing)，以满足生产可用性。
