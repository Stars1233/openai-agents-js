---
title: エージェントの実行
description: Configure and execute agent workflows with the Runner class
---

import { Aside, Code } from '@astrojs/starlight/components';
import helloWorldWithRunnerExample from '../../../../../../examples/docs/hello-world-with-runner.ts?raw';
import helloWorldExample from '../../../../../../examples/docs/hello-world.ts?raw';
import runningAgentsExceptionExample from '../../../../../../examples/docs/running-agents/exceptions1.ts?raw';
import chatLoopExample from '../../../../../../examples/docs/running-agents/chatLoop.ts?raw';
import conversationIdExample from '../../../../../../examples/docs/running-agents/conversationId.ts?raw';
import previousResponseIdExample from '../../../../../../examples/docs/running-agents/previousResponseId.ts?raw';

エージェント はそれ自体では何もしません。`Runner` クラスまたは `run()` ユーティリティでそれらを実行します。

<Code lang="typescript" code={helloWorldExample} title="Simple run" />

カスタム runner が不要な場合は、シングルトンのデフォルト `Runner` インスタンスを実行する `run()` ユーティリティも使えます。

あるいは、独自の runner インスタンスを作成できます:

<Code lang="typescript" code={helloWorldWithRunnerExample} title="Simple run" />

エージェント を実行すると、実行の最終出力と完全な履歴を含む [エージェントの実行結果](/openai-agents-js/ja/guides/results) オブジェクトを受け取ります。

## Runner のライフサイクルと設定

### エージェントループ

Runner の run メソッドを使用する際は、開始エージェント と入力を渡します。入力は文字列（ユーザー メッセージと見なされます）か、OpenAI Responses API のアイテムである入力アイテムのリストのいずれかです。

runner は次のループを実行します:

1. 現在の入力で現在のエージェント のモデルを呼び出す
2. LLM 応答を検査する
   - **Final output** → return
   - **Handoff** → 新しいエージェント に切り替え、蓄積された会話履歴を保持し、1 へ
   - **Tool calls** → ツールを実行し、その結果を会話に追加して 1 へ
3. `maxTurns` に達したら [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) を送出する

<Aside type="note">
  LLM の出力が「final
  output」と見なされるルールは、望ましい型のテキスト出力を生成し、かつ tool
  calls がない場合です。
</Aside>

#### Runner のライフサイクル

アプリ起動時に `Runner` を作成し、リクエスト間で再利用します。このインスタンスはモデルプロバイダーやトレーシングオプションなどのグローバル設定を保持します。まったく異なるセットアップが必要な場合にのみ、別の `Runner` を作成してください。簡単なスクリプトでは、内部でデフォルト runner を使用する `run()` を呼び出すこともできます。

### Run の引数

`run()` メソッドへの入力は、実行を開始する初期エージェント、実行用の入力、およびオプションのセットです。

入力は文字列（ユーザー メッセージと見なされます）、[input items](/openai-agents-js/openai/agents-core/type-aliases/agentinputitem) のリスト、または [Human in the loop (人間の介入)](/openai-agents-js/ja/guides/human-in-the-loop) エージェントを構築している場合は [`RunState`](/openai-agents-js/openai/agents-core/classes/runstate) オブジェクトのいずれかです。

追加のオプションは次のとおりです:

| Option                  | Default | Description                                                                                                                                                            |
| ----------------------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `stream`                | `false` | `true` の場合、呼び出しは `StreamedRunResult` を返し、モデルから届くイベントを随時発行します                                                                           |
| `context`               | –       | すべての tool / guardrail / handoff に転送されるコンテキストオブジェクト。詳しくは [コンテキスト管理](/openai-agents-js/ja/guides/context) を参照                      |
| `maxTurns`              | `10`    | セーフティリミット。到達時に [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) を送出します                                |
| `signal`                | –       | キャンセル用の `AbortSignal`                                                                                                                                           |
| `session`               | –       | セッション永続化の実装。詳しくは [セッション](/openai-agents-js/ja/guides/sessions) を参照                                                                             |
| `sessionInputCallback`  | –       | セッション履歴と新規入力のカスタムマージロジック。モデル呼び出しの前に実行。詳しくは [セッション](/openai-agents-js/ja/guides/sessions) を参照                         |
| `callModelInputFilter`  | –       | モデル呼び出し直前にモデル入力（items + 任意の instructions）を編集するフック。詳しくは [Call model input filter](#call-model-input-filter) を参照                     |
| `toolErrorFormatter`    | –       | モデルに返されるツール承認拒否メッセージをカスタマイズするフック。詳しくは [Tool error formatter](#tool-error-formatter) を参照                                        |
| `reasoningItemIdPolicy` | –       | 以前の実行アイテムをモデル入力に戻す際に reasoning アイテムの `id` を保持または省略するかを制御。詳しくは [Reasoning item ID policy](#reasoning-item-id-policy) を参照 |
| `tracing`               | –       | 実行ごとのトレーシング設定の上書き（例: エクスポート用 API キー）                                                                                                      |
| `errorHandlers`         | –       | サポートされる実行時エラー用ハンドラー（現在は `maxTurns`）。詳しくは [Error handlers](#error-handlers) を参照                                                         |
| `conversationId`        | –       | サーバー 側の会話を再利用（OpenAI Responses API + Conversations API のみ）                                                                                             |
| `previousResponseId`    | –       | 会話を作成せずに直前の Responses API 呼び出しから継続（OpenAI Responses API のみ）                                                                                     |

### ストリーミング

ストリーミングを有効にすると、LLM の実行中にストリーミングイベントも受け取れます。ストリームが開始されると、`StreamedRunResult` には、生成されたすべての新しい出力を含む、実行に関する完全な情報が含まれます。`for await` ループでストリーミングイベントを反復できます。詳細は [ストリーミング](/openai-agents-js/ja/guides/streaming) を参照してください。

### Run の設定

独自の `Runner` インスタンスを作成する場合は、runner を構成するために `RunConfig` オブジェクトを渡せます。

| Field                       | Type                     | Purpose                                                                                               |
| --------------------------- | ------------------------ | ----------------------------------------------------------------------------------------------------- |
| `model`                     | `string \| Model`        | 実行内の **すべての** エージェント に特定のモデルを強制適用                                           |
| `modelProvider`             | `ModelProvider`          | モデル名を解決。デフォルトは OpenAI プロバイダー                                                      |
| `modelSettings`             | `ModelSettings`          | エージェント単位の設定を上書きするグローバルな調整パラメーター                                        |
| `handoffInputFilter`        | `HandoffInputFilter`     | handoff 実行時に入力アイテムを変更（handoff 自体が定義していない場合）                                |
| `inputGuardrails`           | `InputGuardrail[]`       | 最初のユーザー入力に適用される ガードレール                                                           |
| `outputGuardrails`          | `OutputGuardrail[]`      | 最終出力に適用される ガードレール                                                                     |
| `tracingDisabled`           | `boolean`                | OpenAI トレーシングを完全に無効化                                                                     |
| `traceIncludeSensitiveData` | `boolean`                | スパンは発行しつつ、トレースから LLM/ツールの入出力を除外                                             |
| `workflowName`              | `string`                 | Traces ダッシュボードに表示。関連する実行のグルーピングに役立つ                                       |
| `traceId` / `groupId`       | `string`                 | SDK に生成させず、トレース ID またはグループ ID を手動指定                                            |
| `traceMetadata`             | `Record<string, string>` | すべてのスパンに付与する任意のメタデータ                                                              |
| `tracing`                   | `TracingConfig`          | 実行ごとのトレーシング上書き（例: エクスポート用 API キー）                                           |
| `sessionInputCallback`      | `SessionInputCallback`   | この runner 上のすべての実行に対するデフォルトの履歴マージ戦略                                        |
| `callModelInputFilter`      | `CallModelInputFilter`   | 各モデル呼び出し前にモデル入力を編集するグローバルフック                                              |
| `toolErrorFormatter`        | `ToolErrorFormatter`     | モデルに返すツール承認拒否メッセージをカスタマイズするグローバルフック                                |
| `reasoningItemIdPolicy`     | `ReasoningItemIdPolicy`  | 生成アイテムを後続のモデル呼び出しに再生する際、reasoning アイテムの `id` を保持/省略する既定ポリシー |

## 状態と会話の管理

### 会話 / チャットスレッド

`runner.run()`（または `run()` ユーティリティ）への各呼び出しは、アプリケーションレベルの会話における 1 回の **ターン** を表します。エンドユーザー にどの程度の `RunResult` を見せるかは任意です。`finalOutput` のみの場合もあれば、生成されたすべてのアイテムを見せる場合もあります。

<Code lang="typescript" code={chatLoopExample} title="会話履歴を引き継ぐ例" />

インタラクティブ版については [the chat example](https://github.com/openai/openai-agents-js/tree/main/examples/basic/chat.ts) を参照してください。

#### サーバー 管理の会話

各ターンでローカルの全文書を送る代わりに、OpenAI Responses API に会話履歴を保持させることができます。長い会話や複数のサービスを調整する場合に有用です。詳細は [Conversation state guide](https://platform.openai.com/docs/guides/conversation-state?api-mode=responses) を参照してください。

OpenAI は サーバー 側状態を再利用する 2 つの方法を提供します:

##### 1. 会話全体に対する `conversationId`

[Conversations API](https://platform.openai.com/docs/api-reference/conversations/create) で一度会話を作成し、その ID を各ターンで再利用できます。SDK は新たに生成されたアイテムのみを自動的に含めます。

<Code
  lang="typescript"
  code={conversationIdExample}
  title="サーバー 会話の再利用"
/>

##### 2. 直前のターンから継続するための `previousResponseId`

いずれにせよ Responses API のみで開始したい場合は、前のレスポンスから返された ID を用いて各リクエストを連結できます。これにより、完全な会話リソースを作成せずにターン間でコンテキストを維持できます。

<Code
  lang="typescript"
  code={previousResponseIdExample}
  title="previousResponseId による連結"
/>

## フックとカスタマイズ

### Call model input filter

`callModelInputFilter` を使用して、モデルが呼び出される直前にモデル入力を編集します。このフックは現在のエージェント、コンテキスト、（セッション履歴を含む）結合済み入力アイテムを受け取ります。機微データの編集、古いメッセージの削除、追加の system guidance の注入などのために、更新後の `input` 配列と任意の `instructions` を返します。

実行単位では `runner.run(..., { callModelInputFilter })`、デフォルトでは `Runner` の設定（`RunConfig` の `callModelInputFilter`）で指定します。

### Tool error formatter

`toolErrorFormatter` を使用して、ツール呼び出しが拒否された際にモデルに送り返す承認拒否メッセージをカスタマイズできます。これにより、SDK のデフォルトメッセージの代わりに、（たとえばコンプライアンス方針などの）ドメイン固有の表現を返せます。

フォーマッターは実行単位（`runner.run(..., { toolErrorFormatter })`）またはグローバル（`RunConfig` の `new Runner(...)` 内の `toolErrorFormatter`）で設定できます。

フォーマッターは現在 `approval_rejected` イベントに対して実行され、以下を受け取ります:

- `kind`（現在は常に `'approval_rejected'`）
- `toolType`（`'function'`、`'computer'`、`'shell'`、または `'apply_patch'`）
- `toolName`
- `callId`
- `defaultMessage`（SDK のフォールバックメッセージ）
- `runContext`

メッセージを上書きするには文字列を返し、SDK のデフォルトを維持するには `undefined` を返します。フォーマッターが例外を投げる（または非文字列を返す）場合、SDK は警告を記録し、デフォルトの承認拒否メッセージにフォールバックします。

### Reasoning item ID policy

`reasoningItemIdPolicy` を使用して、SDK が以前に生成した実行アイテムを後続のモデル入力用に `AgentInputItem[]` へ戻す際に、reasoning アイテムの `id` フィールドを保持するかどうかを制御します。

これは、SDK が生成済みモデルアイテムを入力として再生する場面に影響します。例:

- 同一実行内での後続のモデル呼び出し（例: ツール実行後）
- 生成アイテムを入力/履歴として再利用する後続ターン
- 保存した `RunState` からの再開
- `result.history` / `result.output` のような派生結果ビュー（いずれもモデル入力形状の配列）

- `'preserve'`（デフォルト）は reasoning アイテムの ID を保持
- `'omit'` は reasoning アイテムから `id` フィールドを入力に戻す前に取り除く
- 非 reasoning アイテムは影響を受けない

変更しないもの:

- 元 のモデル応答（`result.rawResponses`）
- 実行アイテム（`result.newItems`）
- プロバイダーが返すモデルの当該ターン出力

つまり、このポリシーは SDK が以前の生成アイテムから次の入力を構築する際に適用されます。

ポリシーは実行単位（`runner.run(..., { reasoningItemIdPolicy: 'omit' })`）または runner のデフォルト（`new Runner({ reasoningItemIdPolicy: 'omit', ... })`）として設定できます。保存した `RunState` から再開する場合、上書きしない限り以前に解決されたポリシーが再利用されます。

#### `callModelInputFilter` との相互作用

`reasoningItemIdPolicy` は `callModelInputFilter` の前に適用されます。カスタム動作が必要な場合は、`callModelInputFilter` で準備済み入力を検査し、モデル呼び出し前に reasoning ID を再導入または削除できます。

#### `'omit'` を使うとき

再生される reasoning アイテムを ID なしで正規化したい場合（たとえば、転送/再生されるモデル入力を簡潔に保つ、またはアプリのパイプラインで統合要件に合わせるため）に `'omit'` を使用します。

また、バックエンド/プロバイダーが再生された reasoning アイテムをリクエスト検証エラーで拒否する場合（例: フォローアップ入力の reasoning アイテム ID に関連する HTTP `400` エラー）、トラブルシューティングとして有用です。そうしたケースでは、`'omit'` で再生される reasoning ID を削除することで、新規リクエストに対してバックエンドが無効とみなす ID の送信を避けられます。

統合がそれらを受け入れる場合や、再生された入力で reasoning アイテムの ID を保持したい場合は `'preserve'` を維持してください。

## エラーとリカバリー

### エラーハンドラー

`errorHandlers` を使用すると、サポートされる実行時エラーをスローする代わりに最終出力へ変換できます。現在サポートは `maxTurns` のみです。

- `errorHandlers.maxTurns` は最大ターンエラーのみを処理
- `errorHandlers.default` はサポートされる種類のフォールバックとして使用
- ハンドラーは `{ error, context, runData }` を受け取り、`{ finalOutput, includeInHistory? }` を返却可能

### 例外

SDK はキャッチ可能な少数のエラーをスローします:

- [`MaxTurnsExceededError`](/openai-agents-js/openai/agents-core/classes/maxturnsexceedederror) – `maxTurns` に到達
- [`ModelBehaviorError`](/openai-agents-js/openai/agents-core/classes/modelbehaviorerror) – モデルが無効な出力を生成（例: 不正な JSON、未知のツール）
- [`InputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/inputguardrailtripwiretriggered) / [`OutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/outputguardrailtripwiretriggered) – ガードレール 違反
- [`ToolInputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/toolinputguardrailtripwiretriggered) / [`ToolOutputGuardrailTripwireTriggered`](/openai-agents-js/openai/agents-core/classes/tooloutputguardrailtripwiretriggered) – ツール ガードレール 違反
- [`GuardrailExecutionError`](/openai-agents-js/openai/agents-core/classes/guardrailexecutionerror) – ガードレール の実行失敗
- [`ToolTimeoutError`](/openai-agents-js/openai/agents-core/classes/tooltimeouterror) – 関数ツールが `timeoutMs` を超過し、`timeoutBehavior: 'raise_exception'` を使用
- [`ToolCallError`](/openai-agents-js/openai/agents-core/classes/toolcallerror) – タイムアウト以外の理由による関数ツール実行失敗
- [`UserError`](/openai-agents-js/openai/agents-core/classes/usererror) – 設定またはユーザー入力に基づいてスローされる任意のエラー

すべては基底の `AgentsError` クラスを拡張し、現在の実行状態へアクセスするための `state` プロパティを提供する場合があります。

以下は `GuardrailExecutionError` を処理するコード例です。入力ガードレール は実行の最初のユーザー入力にのみ適用されるため、この例では元の入力とコンテキストで実行を再開します。また、保存した状態を再利用して、モデルを再呼び出しせずに出力ガードレール を再試行する方法も示しています:

<Code
  lang="typescript"
  code={runningAgentsExceptionExample}
  title="Guardrail execution error"
/>

入力と出力の再試行について:

- 入力ガードレール は実行の最初のユーザー入力にのみ実行されるため、同じ入力/コンテキストで新しい実行を開始して再試行する必要があります。保存した `state` を渡しても入力ガードレール は再トリガーされません
- 出力ガードレール はモデル応答の後に実行されるため、`GuardrailExecutionError` の保存済み `state` を再利用して、モデルを再呼び出しせずに出力ガードレール を再実行できます

上記の例を実行すると、次の出力が表示されます:

```
Guardrail execution failed (input): Error: Input guardrail failed to complete: Error: Something is wrong!
Math homework input guardrail tripped on retry
Guardrail execution failed (output): Error: Output guardrail failed to complete: Error: Output guardrail crashed.
Output guardrail tripped after retry with saved state
```

---

## 次のステップ

- [モデル](/openai-agents-js/ja/guides/models) の構成方法を学ぶ
- エージェント に [ツール](/openai-agents-js/ja/guides/tools) を提供する
- 本番運用に向けて [ガードレール](/openai-agents-js/ja/guides/guardrails) や [トレーシング](/openai-agents-js/ja/guides/tracing) を追加する
